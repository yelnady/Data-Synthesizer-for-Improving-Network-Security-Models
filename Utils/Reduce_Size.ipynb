{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aad0dba9-cf84-47f5-892e-acbfc0ddf059",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, random, math, pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.utils import shuffle\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "sys.path.append('../DG/gan')\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87680766-eb30-4292-ac87-60b593ff1768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def count_parameters(model):\n",
    "#     return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "# count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9e6b599-d7f1-4f60-a301-b9e49a9f374c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In real data, if flag sum is 1 --> Then no timestep at all. --> So we do remove those ones by converting them to zeros, then remove from the list\n",
    "# In real data, there is no flag of length ZERO\n",
    "def remove_zero_datapoints(X,Y,mask):\n",
    "    indices_non_zero = torch.nonzero(torch.sum(mask,1)-1).squeeze()\n",
    "    return X[indices_non_zero], Y[indices_non_zero], mask[indices_non_zero]\n",
    "\n",
    "def get_one_class(X,Y,Y_label,flag,class_label): # (X, Y, and mask) are the whole dataset that is consisted of many classes, Y is NOT One-Hot Encoded\n",
    "    indices_class_label = np.where(Y_label==class_label)\n",
    "    return X[indices_class_label], Y[indices_class_label], Y_label[indices_class_label],flag[indices_class_label]\n",
    "\n",
    "def get_n_samples(X,Y,flag,n_samples):\n",
    "    randomList = random.sample(range(0, Y.shape[0]), n_samples)\n",
    "    return X[randomList], Y[randomList], flag[randomList]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea4e18a-4ed7-4a10-b645-3446e4f6272f",
   "metadata": {},
   "source": [
    "## Import -> Remove Zeros -> Split classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bcd5c09f-0603-41bc-8fd5-cc218e05b941",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_real = np.load('../data/google/data_train.npz')\n",
    "\n",
    "real_train_X = torch.from_numpy(training_real['data_feature']).float() #[50000, 2500, 9]\n",
    "real_train_Y = torch.from_numpy(training_real['data_attribute']) #[50000,4]\n",
    "real_train_flags = torch.from_numpy(training_real['data_gen_flag'])   # (50000, 2500)\n",
    "\n",
    "real_train_X,real_train_Y,real_train_flags = remove_zero_datapoints(real_train_X,real_train_Y,real_train_flags)\n",
    "real_train_Y_labels = torch.argmax(real_train_Y,1) #[50000,]  \n",
    "\n",
    "\n",
    "real_train_X0, real_train_Y0, real_train_Y_lables0, real_train_flag0 = get_one_class(real_train_X, real_train_Y,\n",
    "                                                                                    real_train_Y_labels,real_train_flags,0)\n",
    "real_train_X1, real_train_Y1, real_train_Y_labels1, real_train_flag1 = get_one_class(real_train_X, real_train_Y,\n",
    "                                                                                    real_train_Y_labels,real_train_flags,1)\n",
    "real_train_X2, real_train_Y2, real_train_Y_labels2, real_train_flag2 = get_one_class(real_train_X, real_train_Y,\n",
    "                                                                                    real_train_Y_labels,real_train_flags,2)\n",
    "real_train_X3, real_train_Y3, real_train_Y_labels3, real_train_flag3 = get_one_class(real_train_X, real_train_Y,\n",
    "                                                                                    real_train_Y_labels,real_train_flags,3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f34a8c04-256d-42dd-be39-a8c39c1efc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- We will divide the train dataset into 50% train, and 0% validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7b9e98b9-aad5-49cb-a7f3-c54611f59b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_class0 = real_train_X0.shape[0]\n",
    "n_class1 = real_train_X1.shape[0]\n",
    "n_class2 = real_train_X2.shape[0]\n",
    "n_class3 = real_train_X3.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e85e8103-b452-4f4b-96a9-e7fc72a0d8c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6250"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_class0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fdb4e385-6172-4bb5-afa1-09c374211734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# real_train_X0,real_train_Y0,real_train_flag0 = get_n_samples(real_train_X0, real_train_Y0,real_train_flag0,\n",
    "#                                                              n_samples=int(n_class0*0.7))\n",
    "\n",
    "# real_train_X1,real_train_Y1,real_train_flag1 = get_n_samples(real_train_X1, real_train_Y1,real_train_flag1,\n",
    "#                                                             n_samples=int(n_class1*0.7))\n",
    "\n",
    "# real_train_X2,real_train_Y2,real_train_flag2 = get_n_samples(real_train_X2, real_train_Y2,real_train_flag2,\n",
    "#                                                             n_samples=int(n_class2*0.7))\n",
    "\n",
    "# real_train_X3,real_train_Y3,real_train_flag3 = get_n_samples(real_train_X3, real_train_Y3,real_train_flag3,\n",
    "#                                                             n_samples=int(n_class3*0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dea19360-ee26-4d69-95dc-38d1eba569e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_train_X_reduced= torch.cat((real_train_X0[:int(n_class0*0.5)],real_train_X1[:int(n_class1*0.5)],\n",
    "                                 real_train_X2[:int(n_class2*0.5)],real_train_X3[:int(n_class3*0.5)]))\n",
    "\n",
    "real_train_Y_reduced= torch.cat((real_train_Y0[:int(n_class0*0.5)],real_train_Y1[:int(n_class1*0.5)],\n",
    "                                 real_train_Y2[:int(n_class2*0.5)],real_train_Y3[:int(n_class3*0.5)]))\n",
    "\n",
    "real_train_flags_reduced = torch.cat((real_train_flag0[:int(n_class0*0.5)],real_train_flag1[:int(n_class1*0.5)],\n",
    "                                      real_train_flag2[:int(n_class2*0.5)],real_train_flag3[:int(n_class3*0.5)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2ac4eb22-ffa6-481e-bc3b-58c6541a17ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_train_X_reduced, real_train_Y_reduced, real_train_flags_reduced = shuffle(real_train_X_reduced, \n",
    "                                                                               real_train_Y_reduced, real_train_flags_reduced )\n",
    "np.savez('../data/google/data_train_reduced',data_feature=real_train_X_reduced,data_attribute= real_train_Y_reduced, \n",
    "         data_gen_flag=real_train_flags_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6520ec8-a564-4ece-b9c5-5724710cd3d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "77ac4991-4b0d-4617-936a-b7ab9f3a7739",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_val_X= torch.cat((real_train_X0[int(n_class0*0.5):],real_train_X1[int(n_class1*0.5):],\n",
    "                       real_train_X2[int(n_class2*0.5):],real_train_X3[int(n_class3*0.5):]))\n",
    "\n",
    "real_val_Y= torch.cat((real_train_Y0[int(n_class0*0.5):],real_train_Y1[int(n_class1*0.5):],\n",
    "                       real_train_Y2[int(n_class2*0.5):],real_train_Y3[int(n_class3*0.5):]))\n",
    "\n",
    "real_val_flags = torch.cat((real_train_flag0[int(n_class0*0.5):],real_train_flag1[int(n_class1*0.5):],\n",
    "                            real_train_flag2[int(n_class2*0.5):],real_train_flag3[int(n_class3*0.5):]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "71e33499-dd82-4354-85c5-d980cf5a4b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_val_X, real_val_Y, real_train_flags_reduced = shuffle(real_val_X ,real_val_Y, real_val_flags )\n",
    "np.savez('../data/google/data_train_val',data_feature=real_val_X,data_attribute= real_val_Y, \n",
    "         data_gen_flag=real_val_flags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10a41c1-5762-4df4-bc75-7e701db9b6c8",
   "metadata": {},
   "source": [
    "# Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "251b572f-216f-4237-82d5-766a2e8f5ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note: I am not going to chanage the variables names, it's the same train\", I just changed the np.load and np.savez\n",
    "training_real = np.load('data/google/data_test.npz')\n",
    "\n",
    "real_train_X = torch.from_numpy(training_real['data_feature']).float() #[50000, 2500, 9]\n",
    "real_train_Y = torch.from_numpy(training_real['data_attribute']) #[50000,4]\n",
    "real_train_flags = torch.from_numpy(training_real['data_gen_flag'])   # (50000, 2500)\n",
    "\n",
    "real_train_X,real_train_Y,real_train_flags = remove_zero_datapoints(real_train_X,real_train_Y,real_train_flags)\n",
    "real_train_Y_labels = torch.argmax(real_train_Y,1) #[50000,]  \n",
    "\n",
    "\n",
    "real_train_X0, real_train_Y0, real_train_Y_lables0, real_train_flag0 = get_one_class(real_train_X, real_train_Y,\n",
    "                                                                                    real_train_Y_labels,real_train_flags,0)\n",
    "real_train_X1, real_train_Y1, real_train_Y_labels1, real_train_flag1 = get_one_class(real_train_X, real_train_Y,\n",
    "                                                                                    real_train_Y_labels,real_train_flags,1)\n",
    "real_train_X2, real_train_Y2, real_train_Y_labels2, real_train_flag2 = get_one_class(real_train_X, real_train_Y,\n",
    "                                                                                    real_train_Y_labels,real_train_flags,2)\n",
    "real_train_X3, real_train_Y3, real_train_Y_labels3, real_train_flag3 = get_one_class(real_train_X, real_train_Y,\n",
    "                                                                                    real_train_Y_labels,real_train_flags,3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab14299-95ee-4e2d-ad4e-4dc02bc67fcd",
   "metadata": {},
   "source": [
    "## n samples from each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e633ea78-8c20-49f4-a6e4-d21e23d5813c",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_train_X0,real_train_Y0,real_train_flag0 = get_n_samples(real_train_X0, real_train_Y0,real_train_flag0,\n",
    "                                                             n_samples=real_train_X0.shape[0]//2)\n",
    "\n",
    "real_train_X1,real_train_Y1,real_train_flag1 = get_n_samples(real_train_X1, real_train_Y1,real_train_flag1,\n",
    "                                                            n_samples=real_train_X1.shape[0]//2)\n",
    "\n",
    "real_train_X2,real_train_Y2,real_train_flag2 = get_n_samples(real_train_X2, real_train_Y2,real_train_flag2,\n",
    "                                                            n_samples=real_train_X2.shape[0]//2)\n",
    "\n",
    "real_train_X3,real_train_Y3,real_train_flag3 = get_n_samples(real_train_X3, real_train_Y3,real_train_flag3,\n",
    "                                                            n_samples=real_train_X3.shape[0]//2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "487fe885-0117-4b33-b263-ae41b9495509",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_train_X_reduced= torch.cat((real_train_X0,real_train_X1,real_train_X2,real_train_X3))\n",
    "real_train_Y_reduced= torch.cat((real_train_Y0,real_train_Y1,real_train_Y2,real_train_Y3))\n",
    "real_train_flags_reduced = torch.cat((real_train_flag0,real_train_flag1,real_train_flag2,real_train_flag3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "298f49c9-5fd2-47a5-908f-a3f3d53fa34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_train_X_reduced, real_train_Y_reduced, real_train_flags_reduced = shuffle(real_train_X_reduced, \n",
    "                                                                               real_train_Y_reduced, real_train_flags_reduced )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb0fb6e2-cd8b-45ad-92ea-f50cce49f227",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('data/google/data_test_reduced',data_feature=real_train_X_reduced,data_attribute= real_train_Y_reduced, \n",
    "         data_gen_flag=real_train_flags_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f1f453-6fe1-473e-928d-73d922f81b91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
