{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3f5ad86-4248-4226-943d-0bc26a03e80e",
   "metadata": {},
   "source": [
    "# Required Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a618acb-32dc-4450-a211-32bba60b2f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, random, math, pickle\n",
    "from time import time\n",
    "import numpy as np\n",
    "import gc\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import MSELoss\n",
    "import torch.nn.functional as F\n",
    "from datetime import timedelta\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "import pytorch_lightning as pl\n",
    "import torchmetrics.functional as FM\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.plugins import DDPPlugin\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "sys.path.append('../DG/gan')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbddef74-d62f-43c4-b7d0-cd6e45ac955b",
   "metadata": {},
   "source": [
    "# Loading Real Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f63d9569-72bc-46f5-987f-64a4d1dbb42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_one_class(X,Y_labels,flag,class_label):\n",
    "    indices_class_label = np.where(Y_labels==class_label)\n",
    "    return X[indices_class_label], Y_labels[indices_class_label], flag[indices_class_label] \n",
    "    \n",
    "def get_n_samples(X,Y_labels,flag,n_samples):\n",
    "    randomList = random.sample(range(0, Y_labels.shape[0]), n_samples)\n",
    "    return X[randomList], Y_labels[randomList], flag[randomList]\n",
    "\n",
    "# In real data, if flag sum is 1 --> Then no timestep at all. \n",
    "            # So we do remove those ones by converting them to zeros, then return only non-zero flags indices\n",
    "# In real data, there is no flag of length ZERO\n",
    "def remove_zero_datapoints(X,Y_labels,flag):\n",
    "    indices_non_zero = torch.nonzero(torch.sum(flag,1)-1).squeeze()\n",
    "    return X[indices_non_zero], Y_labels[indices_non_zero], flag[indices_non_zero]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f052e082-0bba-43c0-9cab-0eab5f14d56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_real = np.load('../data/google/data_train_reduced.npz')\n",
    "\n",
    "real_train_X = torch.from_numpy(training_real['data_feature']).float() #[50000, 2500, 9]\n",
    "real_train_Y = torch.from_numpy(training_real['data_attribute']) #[50000,4]\n",
    "real_train_Y_labels = torch.argmax(real_train_Y,1) #[50000,]  returns a list of the class label, no one hot encoding any more\n",
    "real_train_flags = torch.from_numpy(training_real['data_gen_flag'])   # (50000, 2500)\n",
    "\n",
    "real_train_X,real_train_Y_labels,real_train_flags = remove_zero_datapoints(real_train_X,real_train_Y_labels,real_train_flags)\n",
    "\n",
    "real_train_lengths = torch.sum(real_train_flags,1).long()\n",
    "\n",
    "real_train_masks = real_train_flags == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e442d72-09bb-44db-9d9f-877d37b5a96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_real = np.load('../data/google/data_train_val.npz')\n",
    "\n",
    "real_val_X = torch.from_numpy(val_real['data_feature']).float() #[50000, 2500, 9]\n",
    "real_val_Y = torch.from_numpy(val_real['data_attribute']) #[50000,4]\n",
    "real_val_Y_labels = torch.argmax(real_val_Y,1) #[50000,]  returns a list of the class label, no one hot encoding any more\n",
    "real_val_flags = torch.from_numpy(val_real['data_gen_flag'])   # (50000, 2500)\n",
    "\n",
    "real_val_X,real_val_Y_labels,real_val_flags = remove_zero_datapoints(real_val_X,real_val_Y_labels,real_val_flags)\n",
    "\n",
    "real_val_masks = real_val_flags == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d73b10f-6a20-4101-a0c3-ea0e724f4f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_real = np.load('../data/google/data_test_reduced.npz')\n",
    "\n",
    "real_test_X = torch.from_numpy(test_real['data_feature']).float() #[50000, 2500, 9]\n",
    "real_test_Y = torch.from_numpy(test_real['data_attribute']) #[50000,4]\n",
    "real_test_Y_labels = torch.argmax(real_test_Y,1) #[50000,]  returns a list of the class label, no one hot encoding any more\n",
    "real_test_flags = torch.from_numpy(test_real['data_gen_flag'])   # (50000, 2500)\n",
    "\n",
    "real_test_X,real_test_Y_labels,real_test_flags = remove_zero_datapoints(real_test_X,real_test_Y_labels,real_test_flags)\n",
    "\n",
    "real_test_masks = real_test_flags == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13146a91-fb12-4c1f-bae7-bf651e107b39",
   "metadata": {},
   "source": [
    "# Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e55d3bd8-0106-496b-97ad-9ca611872d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "B = real_train_X.size(0)\n",
    "S = real_train_X.size(1)\n",
    "E = real_train_X.size(2)\n",
    "\n",
    "# 1- Shift the targets\n",
    "Input_shifted = real_train_X[:,1:]\n",
    "Zero_at_the_end = torch.zeros((B,1,E))\n",
    "targets = torch.cat((Input_shifted,Zero_at_the_end),1) # real_train_X shifted to the left one timestep\n",
    "\n",
    "targets=  targets[:,:400]\n",
    "real_train_masks = real_train_masks[:,:400]\n",
    "real_train_X = real_train_X[:,:400]\n",
    "real_train_flags = real_train_flags[:,:400]\n",
    "real_train_lengths = torch.sum(real_train_flags,1).long()\n",
    "\n",
    "\n",
    "S = real_train_X.size(1)\n",
    "\n",
    "params_dataloader = {'shuffle': True,'num_workers':8 ,'batch_size':128} # No need to shuffle rn, they are all the same class\n",
    "# \"num_workers\" is how many subprocesses to use for data loading.\n",
    "dataset = torch.utils.data.TensorDataset(real_train_X, targets, real_train_lengths, real_train_masks)\n",
    "train_dataloader  = torch.utils.data.DataLoader(dataset, **params_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41edd324-ba94-4101-bbe8-bea5a2ef2364",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation Dataset and DataLoader \n",
    "\n",
    "B = real_val_X.size(0)\n",
    "S = real_val_X.size(1)\n",
    "E = real_val_X.size(2)\n",
    "\n",
    "Input_shifted = real_val_X[:,1:]\n",
    "Zero_at_the_end = torch.zeros((B,1,E))\n",
    "targets = torch.cat((Input_shifted,Zero_at_the_end),1) # real_train_X shifted to the left one timestep\n",
    "\n",
    "targets=  targets[:,:400]\n",
    "real_val_masks = real_val_masks[:,:400]\n",
    "real_val_X = real_val_X[:,:400]\n",
    "\n",
    "real_val_flags = real_val_flags[:,:400]\n",
    "real_val_lengths = torch.sum(real_val_flags,1).long()\n",
    "\n",
    "S = real_val_X.size(1)\n",
    "\n",
    "params_dataloader = {'shuffle': False,'num_workers':8 ,'batch_size':128} # No need to shuffle rn, they are all the same class\n",
    "dataset = torch.utils.data.TensorDataset(real_val_X, targets, real_val_lengths, real_val_masks)\n",
    "val_dataloader  = torch.utils.data.DataLoader(dataset, **params_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a66c26-3e0a-44e5-9c89-7075e49907cc",
   "metadata": {},
   "source": [
    "# TST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f896001-4f2c-4818-9525-e59267dfb279",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding2(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        \"\"\"\n",
    "        Inputs\n",
    "            d_model - Hidden dimensionality of the input.\n",
    "            max_len - Maximum length of a sequence to expect.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # Create matrix of [SeqLen, HiddenDim] representing the positional encoding for max_len inputs\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "\n",
    "        # register_buffer => Tensor which is not a parameter, but should be part of the modules state.\n",
    "        # Used for tensors that need to be on the same device as the module.\n",
    "        # persistent=False tells PyTorch to not add the buffer to the state dict (e.g. when we save the model)\n",
    "        self.register_buffer('pe', pe) # ,persistent=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:, :x.size(1)]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e147f88-9c5e-468e-bfb2-6e674538d06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesTransformer(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, n_features=9, d_model=256, n_heads=8, n_hidden=256, n_layers=8, dropout=0.0, S=400):\n",
    "        super().__init__()\n",
    "        self.model_type = 'Time Series Transformer Model'\n",
    "        self.InputLinear = nn.Linear(n_features, d_model)\n",
    "        \n",
    "        self.positional_encoding = PositionalEncoding(d_model, dropout)\n",
    "        encoder_layers = TransformerEncoderLayer(d_model, n_heads, n_hidden, dropout)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layers, n_layers)\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.n_features = n_features\n",
    "        \n",
    "        self.OutputLinear = nn.Linear(d_model, n_features) # The output of the encoder is similar to the input of the encoder, both are (B,S,d_model)\n",
    "        self.init_weights()\n",
    "     \n",
    "        \n",
    "    def generate_square_subsequent_mask(self, sz):\n",
    "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "        mask = mask.float().masked_fill(mask == 0, float(-1e6)).masked_fill(mask == 1, float(0.0))\n",
    "        return mask \n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        self.InputLinear.weight.data.uniform_(-initrange, initrange)\n",
    "        self.OutputLinear.bias.data.zero_()\n",
    "        self.OutputLinear.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, src, src_mask,padding_mask):\n",
    "        src = self.InputLinear(src) * math.sqrt(self.d_model)\n",
    "        src = self.positional_encoding(src)\n",
    "        output = self.transformer_encoder(src, src_mask,padding_mask)\n",
    "        output = self.OutputLinear(output.permute(1,0,2))\n",
    "        return output \n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "\n",
    "        X,target,lengths,padding_mask = batch\n",
    "        src_mask = self.generate_square_subsequent_mask(S).cuda()\n",
    "        X = X.permute(1,0,2)\n",
    "        padding_mask = torch.cat((torch.zeros((X.shape[1],2),dtype=torch.bool), (torch.ones((X.shape[1],398),dtype=torch.bool))),1).cuda()\n",
    "        class_probs  = self(X,None,padding_mask)\n",
    "        lengths -=1\n",
    "        loss = nn.CrossEntropyLoss()(class_probs, lengths )\n",
    "        \n",
    "        return {'loss': loss,} # will call loss.backward() on what we return exactly. \n",
    "    \n",
    "    def training_epoch_end(self, outputs):\n",
    "        if((self.current_epoch+1)%100==0):\n",
    "            torch.save(self.state_dict(), 'W_transformer_token_V9')\n",
    "        print(\"Epoch Loss:\",torch.stack([x[\"loss\"] for x in outputs]).mean().item())\n",
    "\n",
    "    # Lightning disables gradients, puts model in eval mode, and does everything needed for validation.\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        X,target,lengths,padding_mask = batch\n",
    "        src_mask = self.generate_square_subsequent_mask(S).cuda()\n",
    "        X = X.permute(1,0,2)\n",
    "        padding_mask = torch.cat((torch.zeros((X.shape[1],2),dtype=torch.bool), (torch.ones((X.shape[1],398),dtype=torch.bool))),1).cuda()\n",
    "        \n",
    "        class_probs  = self(X,None,padding_mask)\n",
    "        lengths -=1\n",
    "        loss = nn.CrossEntropyLoss()(class_probs, lengths )\n",
    "        \n",
    "        self.log('val_loss', loss)\n",
    "        return {'val_loss': loss,} # We may return the predictions themselves\n",
    "    \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        print(\"Validation Loss:\",torch.stack([x[\"val_loss\"] for x in outputs]).mean().item())\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=0.0001)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8f62e064-96dd-4b87-b0ff-57de7e49b1e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([400, 400])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.generate_square_subsequent_mask(S).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "164179e2-73f2-48af-a11a-5faa94faaa84",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = TimeSeriesTransformer() \n",
    "ck = torch.load('../lightning_logs/version_19/checkpoints/epoch=399-step=76799.ckpt')['state_dict']\n",
    "model.load_state_dict(ck)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "model.OutputLinear  = nn.Sequential(nn.Flatten(1),nn.Linear(256*400,400) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b467803-ae24-4f4f-8942-42fd65352924",
   "metadata": {},
   "source": [
    "# Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2e4d0416-a2b0-4b24-911a-5d6cefcbfe59",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeSeriesTransformer(\n",
       "  (InputLinear): Linear(in_features=9, out_features=256, bias=True)\n",
       "  (positional_encoding): PositionalEncoding(\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "  )\n",
       "  (transformer_encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.0, inplace=False)\n",
       "        (dropout2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (1): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.0, inplace=False)\n",
       "        (dropout2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (2): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.0, inplace=False)\n",
       "        (dropout2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (3): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.0, inplace=False)\n",
       "        (dropout2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (4): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.0, inplace=False)\n",
       "        (dropout2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (5): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.0, inplace=False)\n",
       "        (dropout2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (6): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.0, inplace=False)\n",
       "        (dropout2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (7): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.0, inplace=False)\n",
       "        (dropout2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (OutputLinear): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=102400, out_features=400, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ck = torch.load('lightning_logs/version_108/checkpoints/epoch=2-step=575.ckpt')['state_dict']\n",
    "# # The minimum loss was  1.4949455261230469, but if all data available not only the first two timesteps, it was 0.3219143748283386\n",
    "# model.load_state_dict(ck)\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b49c5487-880e-4887-91fc-d1ccef558e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = 300\n",
    "# b = 500\n",
    "# src_mask = model.generate_square_subsequent_mask(S)\n",
    "# x = torch.cat((real_train_X[a:b,:2],torch.zeros((200,398,9))),1)\n",
    "# padding_mask = torch.cat((real_train_masks[a:b,:2],torch.ones((200,398),dtype=torch.bool)),1)\n",
    "\n",
    "# # x= real_train_X[2400:2600]\n",
    "# # padding_mask = real_train_masks[2400:2600]\n",
    "# testt = model(x.permute(1,0,2),None,padding_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3b7e313d-a948-47c8-bc72-99918eda6f3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for i,j in zip(F.softmax(testt).argmax(1),real_train_lengths[a:b]):\n",
    "#     print(i,j)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316622a3-84a9-4f53-9f01-15f310fd142b",
   "metadata": {},
   "source": [
    "# Classifier - MLP (not pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "43565713-62c8-4348-86c9-4fe86fcf510e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MLPModel(pl.LightningModule):\n",
    "    def __init__(self,n_features=9,n_timesteps=2,n_hidden=128,n_output=400):\n",
    "        super().__init__()\n",
    "        # need to be (self) in order to be optimized and part of model\n",
    "        self.model = nn.Sequential(\n",
    "                  nn.Flatten(start_dim=1),\n",
    "                  nn.Linear(n_features*n_timesteps,1024),\n",
    "                  nn.ReLU(),\n",
    "                    nn.Linear(1024,256),\n",
    "                  nn.ReLU(),\n",
    "                  nn.Linear(256,n_output),\n",
    "                )\n",
    "    def forward(self,x):\n",
    "        return self.model(x)\n",
    "    \n",
    "     \n",
    "    def training_step(self, batch, batch_idx):\n",
    "\n",
    "        X,target,lengths,padding_mask = batch\n",
    "        #padding_mask = torch.cat((torch.zeros((X.shape[1],2),dtype=torch.bool), (torch.ones((X.shape[1],398),dtype=torch.bool))),1).cuda()\n",
    "        \n",
    "        class_probs  = self(X[:,:2])\n",
    "        lengths -=1\n",
    "        loss = nn.CrossEntropyLoss()(class_probs, lengths )\n",
    "        \n",
    "        return {'loss': loss,} # will call loss.backward() on what we return exactly. \n",
    "    \n",
    "    def training_epoch_end(self, outputs):\n",
    "        if((self.current_epoch+1)%100==0):\n",
    "            torch.save(self.state_dict(), 'W_transformer_token_V9.1')\n",
    "        print(\"Epoch Loss:\",torch.stack([x[\"loss\"] for x in outputs]).mean().item())\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b06a9d8f-998c-4cfc-8b16-04a967c51342",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name  | Type       | Params\n",
      "-------------------------------------\n",
      "0 | model | Sequential | 1.4 M \n",
      "-------------------------------------\n",
      "1.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.4 M     Total params\n",
      "5.737     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e01eff8e5184ddab3d20828c585d3c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Loss: 2.7630443572998047\n",
      "Epoch Loss: 2.2068989276885986\n",
      "Epoch Loss: 2.123223304748535\n",
      "Epoch Loss: 2.08376145362854\n",
      "Epoch Loss: 2.04807186126709\n",
      "Epoch Loss: 2.033076286315918\n",
      "Epoch Loss: 2.014946460723877\n",
      "Epoch Loss: 2.011458158493042\n",
      "Epoch Loss: 1.9921491146087646\n",
      "Epoch Loss: 1.981168508529663\n",
      "Epoch Loss: 1.9713590145111084\n",
      "Epoch Loss: 1.9637658596038818\n",
      "Epoch Loss: 1.957294225692749\n",
      "Epoch Loss: 1.9503129720687866\n",
      "Epoch Loss: 1.9459199905395508\n",
      "Epoch Loss: 1.9419441223144531\n",
      "Epoch Loss: 1.9342927932739258\n",
      "Epoch Loss: 1.9297717809677124\n",
      "Epoch Loss: 1.9208972454071045\n",
      "Epoch Loss: 1.9157543182373047\n",
      "Epoch Loss: 1.9099369049072266\n",
      "Epoch Loss: 1.8982248306274414\n",
      "Epoch Loss: 1.8949275016784668\n",
      "Epoch Loss: 1.8950470685958862\n",
      "Total Time (in minutes) is 0:01:24.508482\n",
      "/rdata/yelnady/DoppelGANger/Token/lightning_logs/version_116/checkpoints/epoch=24-step=4798.ckpt\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    time_all = time()\n",
    "    mlp_model = MLPModel()\n",
    "    checkpoint_callback = ModelCheckpoint()\n",
    "    trainer = pl.Trainer(gpus=1,max_epochs=100, progress_bar_refresh_rate=50,check_val_every_n_epoch=3,\n",
    "                        callbacks=[checkpoint_callback],)\n",
    "    trainer.fit(mlp_model,train_dataloader)\n",
    "    print(\"Total Time (in minutes) is {}\".format( timedelta(seconds=(time()-time_all))))\n",
    "    print(checkpoint_callback.best_model_path)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c498291b-f99f-4f99-902b-4bd5cf178d40",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea22afa8-9519-4be3-a0e6-64da240005c0",
   "metadata": {},
   "source": [
    "**Notes on EarlyStopping:**\n",
    "- The EarlyStopping callback runs at the **end of every validation epoch**, which, under the default configuration, happen after **every training epoch**.\n",
    "-  However, the frequency of validation can be modified by setting various parameters in the Trainer, for example **check_val_every_n_epoch and val_check_interval**.\n",
    "- Note that the **patience** parameter counts the number of **validation epochs with no improvement**, and **not the number of training epochs**. \n",
    "    - Therefore, with parameters **check_val_every_n_epoch=10 and patience=3**, the trainer will perform at least **40 training epochs before being stopped**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a4a2c98b-72bd-483a-8c15-542e2f5f6231",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name                | Type               | Params\n",
      "-----------------------------------------------------------\n",
      "0 | InputLinear         | Linear             | 2.6 K \n",
      "1 | positional_encoding | PositionalEncoding | 0     \n",
      "2 | transformer_encoder | TransformerEncoder | 3.2 M \n",
      "3 | OutputLinear        | Sequential         | 205 K \n",
      "-----------------------------------------------------------\n",
      "205 K     Trainable params\n",
      "3.2 M     Non-trainable params\n",
      "3.4 M     Total params\n",
      "13.496    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbfd595453054dc6b35b26616ac6cbfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 6.091458320617676\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8ee836ba810451fbb7d600a0844aeac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Loss: 3.2524185180664062\n",
      "Epoch Loss: 2.2478199005126953\n",
      "Epoch Loss: 2.161529541015625\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 3.3052306175231934\n",
      "Epoch Loss: 2.11668062210083\n",
      "Epoch Loss: 2.0964949131011963\n",
      "Epoch Loss: 2.0840518474578857\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 3.475083351135254\n",
      "Epoch Loss: 2.07138991355896\n",
      "Epoch Loss: 2.0565011501312256\n",
      "Epoch Loss: 2.05267071723938\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 3.5716495513916016\n",
      "Epoch Loss: 2.044581174850464\n",
      "Epoch Loss: 2.0346930027008057\n",
      "Epoch Loss: 2.0320231914520264\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 3.625115156173706\n",
      "Epoch Loss: 2.0270254611968994\n",
      "Epoch Loss: 2.016049861907959\n",
      "Epoch Loss: 2.0125222206115723\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 3.684926748275757\n",
      "Epoch Loss: 2.0080485343933105\n",
      "Epoch Loss: 2.0049023628234863\n",
      "Epoch Loss: 1.998694658279419\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 3.730433464050293\n",
      "Epoch Loss: 1.9966742992401123\n",
      "Epoch Loss: 1.988674521446228\n",
      "Epoch Loss: 1.9874091148376465\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 3.7565619945526123\n",
      "Epoch Loss: 1.985229253768921\n",
      "Epoch Loss: 1.9836041927337646\n",
      "Epoch Loss: 1.9827523231506348\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 3.786376476287842\n",
      "Epoch Loss: 1.976083755493164\n",
      "Epoch Loss: 1.970283031463623\n",
      "Epoch Loss: 1.9712257385253906\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 3.8001856803894043\n",
      "Epoch Loss: 1.972574234008789\n",
      "Epoch Loss: 1.9662559032440186\n",
      "Epoch Loss: 1.9608850479125977\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 3.828634738922119\n",
      "Epoch Loss: 1.9601223468780518\n",
      "Epoch Loss: 1.9567625522613525\n",
      "Epoch Loss: 1.9576104879379272\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 3.8663177490234375\n",
      "Epoch Loss: 1.9549705982208252\n",
      "Epoch Loss: 1.9528136253356934\n",
      "Epoch Loss: 1.9532811641693115\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 3.875904083251953\n",
      "Epoch Loss: 1.9513275623321533\n",
      "Epoch Loss: 1.9467430114746094\n",
      "Epoch Loss: 1.9440553188323975\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 3.906177520751953\n",
      "Epoch Loss: 1.9465984106063843\n",
      "Epoch Loss: 1.9427865743637085\n",
      "Epoch Loss: 1.9402536153793335\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 3.890829086303711\n",
      "Epoch Loss: 1.9435124397277832\n",
      "Epoch Loss: 1.9408477544784546\n",
      "Epoch Loss: 1.9376882314682007\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 3.9257469177246094\n",
      "Epoch Loss: 1.9347093105316162\n",
      "Epoch Loss: 1.9337749481201172\n",
      "Epoch Loss: 1.9339559078216553\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 3.934978485107422\n",
      "Epoch Loss: 1.931655764579773\n",
      "Epoch Loss: 1.9308128356933594\n",
      "Epoch Loss: 1.9263185262680054\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 3.948209285736084\n",
      "Epoch Loss: 1.9263191223144531\n",
      "Epoch Loss: 1.9267730712890625\n",
      "Epoch Loss: 1.9249358177185059\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 3.9626994132995605\n",
      "Epoch Loss: 1.928309440612793\n",
      "Epoch Loss: 1.9228929281234741\n",
      "Epoch Loss: 1.9222674369812012\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 3.9650092124938965\n",
      "Epoch Loss: 1.9203437566757202\n",
      "Epoch Loss: 1.9167022705078125\n",
      "Epoch Loss: 1.9171184301376343\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 3.982018232345581\n",
      "Epoch Loss: 1.9175441265106201\n",
      "Epoch Loss: 1.9160118103027344\n",
      "Epoch Loss: 1.9131884574890137\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 3.991971969604492\n",
      "Epoch Loss: 1.9176900386810303\n",
      "Epoch Loss: 1.910217046737671\n",
      "Epoch Loss: 1.913451910018921\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 3.9965872764587402\n",
      "Epoch Loss: 1.9134769439697266\n",
      "Epoch Loss: 1.9105905294418335\n",
      "Epoch Loss: 1.9067248106002808\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 4.010469436645508\n",
      "Epoch Loss: 1.9113296270370483\n",
      "Epoch Loss: 1.9083633422851562\n",
      "Epoch Loss: 1.9048479795455933\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 4.00966215133667\n",
      "Epoch Loss: 1.90632963180542\n",
      "Epoch Loss: 1.907663106918335\n",
      "Epoch Loss: 1.9059743881225586\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 4.025118350982666\n",
      "Epoch Loss: 1.9039463996887207\n",
      "Epoch Loss: 1.9058631658554077\n",
      "Epoch Loss: 1.8995327949523926\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 4.035505294799805\n",
      "Epoch Loss: 1.902456283569336\n",
      "Epoch Loss: 1.8992919921875\n",
      "Epoch Loss: 1.8987665176391602\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 4.0524210929870605\n",
      "Epoch Loss: 1.8947362899780273\n",
      "Epoch Loss: 1.904262900352478\n",
      "Epoch Loss: 1.8983545303344727\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 4.0392608642578125\n",
      "Epoch Loss: 1.8942921161651611\n",
      "Epoch Loss: 1.8970961570739746\n",
      "Epoch Loss: 1.8928836584091187\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 4.052065372467041\n",
      "Epoch Loss: 1.8952707052230835\n",
      "Epoch Loss: 1.897621989250183\n",
      "Epoch Loss: 1.8892712593078613\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 4.063403606414795\n",
      "Epoch Loss: 1.8936184644699097\n",
      "Epoch Loss: 1.8957316875457764\n",
      "Epoch Loss: 1.8922133445739746\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 4.064950942993164\n",
      "Epoch Loss: 1.891387939453125\n",
      "Epoch Loss: 1.8935546875\n",
      "Epoch Loss: 1.8899495601654053\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 4.088421821594238\n",
      "Epoch Loss: 1.8908867835998535\n",
      "Epoch Loss: 1.8894509077072144\n",
      "Epoch Loss: 1.8870067596435547\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 4.082433700561523\n",
      "Epoch Loss: 1.8845741748809814\n",
      "Total Time (in minutes) is 0:09:32.818214\n",
      "/rdata/yelnady/DoppelGANger/Token/lightning_logs/version_111/checkpoints/epoch=2-step=575.ckpt\n"
     ]
    }
   ],
   "source": [
    "# RuntimeError: CUDA error: device-side assert triggered --> The problem it needs to be 0-399 not 1-400\n",
    "def main():\n",
    "    # pl.seed_everything(42, workers=True) --> sets seeds for numpy, torch, python.random and PYTHONHASHSEED.\n",
    "    time_all = time()\n",
    "\n",
    "    \n",
    "    early_stop_callback = EarlyStopping(monitor='val_loss',patience=5, verbose=False, mode='min')\n",
    "    checkpoint_callback = ModelCheckpoint()\n",
    "#     trainer = pl.Trainer(gpus=2,max_epochs=400, progress_bar_refresh_rate=50,accelerator ='ddp',\n",
    "#                         callbacks=[early_stop_callback,checkpoint_callback]\n",
    "#                          ,plugins=DDPPlugin(find_unused_parameters=False,check_val_every_n_epoch=2))\n",
    "    \n",
    "    \n",
    "    trainer = pl.Trainer(gpus=1,max_epochs=100, progress_bar_refresh_rate=50,check_val_every_n_epoch=3,\n",
    "                        callbacks=[checkpoint_callback],)\n",
    "    trainer.fit(model,train_dataloader,val_dataloader)\n",
    "    print(\"Total Time (in minutes) is {}\".format( timedelta(seconds=(time()-time_all))))\n",
    "    print(checkpoint_callback.best_model_path)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6bee552c-0365-4425-a262-692d0185f5ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
