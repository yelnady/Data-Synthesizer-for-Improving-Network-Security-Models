{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd804dce",
   "metadata": {},
   "source": [
    "# Required Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4fde077",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, random, math, pickle\n",
    "from time import time\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import MSELoss\n",
    "import seaborn as sns\n",
    "from tensorboard import default\n",
    "import torch.nn.functional as F\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "sys.path.append('DG/gan')\n",
    "import gc\n",
    "print(device)\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42fe389b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total    : 25396838400\n",
      "free     : 21214330880\n",
      "used     : 4182507520\n"
     ]
    }
   ],
   "source": [
    "from pynvml import *\n",
    "nvmlInit()\n",
    "h = nvmlDeviceGetHandleByIndex(1)\n",
    "info = nvmlDeviceGetMemoryInfo(h)\n",
    "print(f'total    : {info.total}')\n",
    "print(f'free     : {info.free}')\n",
    "print(f'used     : {info.used}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fafd34f",
   "metadata": {},
   "source": [
    "# Import Real Training Data to Generate New Data from it.\n",
    "\n",
    "### Actual Distribution\n",
    "- Class0: 6250\n",
    "- Class1: 16124\n",
    "- Class2: 21273\n",
    "- Class3: 5278"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da9cee8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_one_class(X,Y,flag,class_label): # (X, Y, and flag) are the whole dataset that is consisted of many classes, Y is NOT One-Hot Encoded\n",
    "    indices_class_label = np.where(Y==class_label)\n",
    "    X,Y,flag = X[indices_class_label], Y[indices_class_label], flag[indices_class_label] \n",
    "    indices_non_zero = torch.nonzero(torch.sum(flag,1)-1).squeeze()\n",
    "    return X[indices_non_zero], Y[indices_non_zero], flag[indices_non_zero]\n",
    "\n",
    "def get_n_samples(X,Y,flag,n_samples):\n",
    "    randomList = random.sample(range(0, Y.shape[0]), n_samples)\n",
    "    return X[randomList], Y[randomList], flag[randomList]\n",
    "\n",
    "# In real data, if flag sum is 1 --> Then no timestep at all. --> So we do remove those ones by converting them to zeros, then remove from the list\n",
    "# In real data, there is no flag of length ZERO\n",
    "def remove_zero_datapoints(X,Y,flag):\n",
    "    indices_non_zero = torch.nonzero(torch.sum(flag,1)-1).squeeze()\n",
    "    return X[indices_non_zero], Y[indices_non_zero], flag[indices_non_zero]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98039037",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_real = np.load('../data/google/data_train_reduced.npz')\n",
    "\n",
    "real_train_X = torch.from_numpy(training_real['data_feature']).float() #[50000, 2500, 9]\n",
    "real_train_Y = torch.from_numpy(training_real['data_attribute']) #[50000,4]\n",
    "real_train_Y_labels = torch.argmax(real_train_Y,1) #[50000,]  returns a list of the class label, no one hot encoding any more\n",
    "real_train_flags = torch.from_numpy(training_real['data_gen_flag'])   # (50000, 2500)\n",
    "\n",
    "#------------------------------------------------------------------Loading One Class------------------------------------------------\n",
    "real_train_X, real_train_Y_labels, real_train_flags= remove_zero_datapoints(real_train_X, real_train_Y_labels, real_train_flags)\n",
    "\n",
    "# The pading mask need to be inverted \n",
    "\n",
    "padding_mask = real_train_flags == 0 # True when padding, False when considering\n",
    "\n",
    "real_train_lengths = torch.sum(real_train_flags,1).long()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee02bed",
   "metadata": {},
   "source": [
    "# PyTorch Transformer Model\n",
    "\n",
    "- Later, we need to remove this from here and put in a separate folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e64930ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54c4f37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesTransformer(nn.Module):\n",
    "\n",
    "    def __init__(self, n_features=9, n_auxiliary=3, d_model=256, n_heads=8, n_hidden=256, n_layers=8, dropout=0.0, S=400):\n",
    "        super().__init__()\n",
    "        self.model_type = 'Time Series Transformer Model'\n",
    "        self.InputLinear = nn.Linear(n_features, d_model)\n",
    "        \n",
    "        self.positional_encoding = PositionalEncoding(d_model, dropout)\n",
    "        encoder_layers = TransformerEncoderLayer(d_model, n_heads, n_hidden, dropout)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layers, n_layers)\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.n_features = n_features\n",
    "        \n",
    "        self.OutputLinear = nn.Linear(d_model, n_features) # The output of the encoder is similar to the input of the encoder, both are (B,S,d_model)\n",
    "        self.AuxiliaryLinear = nn.Linear(d_model, n_auxiliary) \n",
    "        self.init_weights()\n",
    "        self.activation = nn.Sigmoid()\n",
    "        \n",
    "    def generate_square_subsequent_mask(self, sz):\n",
    "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "        mask = mask.float().masked_fill(mask == 0, float(-1e6)).masked_fill(mask == 1, float(0.0))\n",
    "        return mask \n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        self.InputLinear.weight.data.uniform_(-initrange, initrange)\n",
    "        self.OutputLinear.bias.data.zero_()\n",
    "        self.OutputLinear.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, src, src_mask,padding_mask):\n",
    "        src = self.InputLinear(src) * math.sqrt(self.d_model)\n",
    "        src = self.positional_encoding(src)\n",
    "        output = self.transformer_encoder(src, src_mask,padding_mask)\n",
    "        \n",
    "        output1 = self.OutputLinear(output)\n",
    "        output1 = self.activation(output1) # output[...,:9] --> Actual 9 values\n",
    "        \n",
    "        output2 = self.AuxiliaryLinear(output) #aux\n",
    "        return output1,output2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ed9979-8e53-4d52-b099-774e18ed4c42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c89ab56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = TimeSeriesTransformer().to(device)\n",
    "\n",
    "# ck = torch.load('lightning_logs/version_36/checkpoints/epoch=257-step=49535.ckpt')['state_dict']\n",
    "# model.load_state_dict(ck)\n",
    "\n",
    "model.load_state_dict(torch.load('W_transformer_aux_V6'))\n",
    "model.eval()\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46c5d0c",
   "metadata": {},
   "source": [
    "# Generating New Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91cd32d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################# The following is the generating part #################################\n",
    "\n",
    "# Returns: X (The data)\n",
    "# Returns: masks (e.g. [False,Flase,True,True,True,....,True]), False is the actual Data\n",
    "\n",
    "resulted_masks = []\n",
    "generated_dataset_Y=[]\n",
    "generated_dataset_X=[]\n",
    "\n",
    "def generate_dataset(X,Y,masks,n_seed,n_samples,max_length):\n",
    "    for n in range(n_samples):\n",
    "        \n",
    "        datapoint,y,mask = get_n_samples(X,Y,masks,n_samples=1) # The first 10 timesteps of just one sample\n",
    "        datapoint = datapoint[:,:n_seed].permute(1,0,2) \n",
    "        datapoint_len = torch.sum(~mask) #Flip and count, you will get the actual length to generate likewise\n",
    "        mask = mask[:,:n_seed] \n",
    "        E = datapoint.size(2)\n",
    "        S = datapoint.size(0)\n",
    "        #print(datapoint_len)\n",
    "        for t in range(max_length-n_seed): # Loop until 400 timesteps\n",
    "            src_mask = model.generate_square_subsequent_mask(S)\n",
    "            Y_predicted, aux_predicted = model(datapoint.to(device),src_mask.to(device),mask.to(device))\n",
    "            Y_predicted = Y_predicted.cpu()\n",
    "            one_new_timestep=Y_predicted[-1].unsqueeze(0)\n",
    "            #print(F.softmax(aux_predicted[-1]))\n",
    "            #print(aux_predicted.squeeze().shape)\n",
    "            #print(F.softmax(aux_predicted[-1]).argmax().item())\n",
    "            if F.softmax(aux_predicted[-1]).argmax().item() == 2:\n",
    "                #print(datapoint_len,S)\n",
    "                datapoint = torch.cat((datapoint,torch.zeros((max_length-S,1,E)))).cpu()# Pad remainings with zero\n",
    "                mask =  torch.cat((mask,torch.full((1,max_length-S),True)),1)\n",
    "        \n",
    "                break\n",
    "            \n",
    "            datapoint = torch.cat((datapoint,one_new_timestep)) # add the forecasted timestep\n",
    "            mask = torch.cat((mask,torch.tensor([[False]])),1 )\n",
    "            S = datapoint.size(0)\n",
    "            \n",
    "        resulted_masks.append(mask.numpy())\n",
    "        generated_dataset_X.append(datapoint.permute(1,0,2).squeeze().detach().numpy())\n",
    "        generated_dataset_Y.append(y.item())\n",
    "        del mask\n",
    "        del datapoint\n",
    "        del one_new_timestep\n",
    "        gc.collect(),torch.cuda.empty_cache()\n",
    "        \n",
    "        if (n%100==0):\n",
    "            print('{}/{}'.format(n,n_samples))\n",
    "        if ((n+1)%1000==0):\n",
    "             np.savez('npz_transformer_token_V7',X=generated_dataset_X,masks= resulted_masks,Y=generated_dataset_Y)\n",
    "\n",
    "max_length = 400\n",
    "n_seed = 2\n",
    "# Padding Mask Fed here is the Mask where \"False is Real Data\", True is masked and ignore them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a3c81528-2a26-43a9-92c7-a13b65684ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to make sure everything is calculated correctly in softmax and argmax\n",
    "\n",
    "# x = torch.rand((2,3))\n",
    "# print(x)\n",
    "# print(F.softmax(x).argmax(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8a648f5c-83e8-4843-8530-e257e5144aff",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/rhome/yelnady/.local/lib/python3.6/site-packages/ipykernel_launcher.py:25: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/rhome/yelnady/.local/lib/python3.6/site-packages/ipykernel_launcher.py:28: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.5344e-07, 8.1291e-01, 1.8709e-01]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.4277e-07, 9.9996e-01, 3.4966e-05]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.3132e-06, 9.9999e-01, 3.8869e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.0524e-06, 9.9797e-01, 2.0261e-03]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[3.1014e-07, 9.9643e-01, 3.5720e-03]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[2.4865e-07, 9.1832e-01, 8.1685e-02]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[5.2711e-07, 9.9951e-01, 4.8613e-04]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.3706e-07, 9.8027e-01, 1.9725e-02]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.8341e-07, 9.9995e-01, 4.6675e-05]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[8.9503e-07, 9.8116e-01, 1.8835e-02]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[3.4782e-06, 9.9045e-01, 9.5506e-03]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[8.9126e-06, 9.9935e-01, 6.4417e-04]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.0308e-05, 9.9753e-01, 2.4573e-03]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.0764e-05, 9.9683e-01, 3.1633e-03]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[4.8665e-06, 9.9948e-01, 5.1611e-04]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.5542e-06, 9.8623e-01, 1.3767e-02]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[7.0820e-06, 8.4905e-01, 1.5094e-01]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[3.6828e-05, 9.3507e-01, 6.4890e-02]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.8264e-04, 8.9027e-01, 1.0954e-01]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[5.4029e-05, 8.4908e-01, 1.5086e-01]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[3.8744e-06, 9.7372e-01, 2.6275e-02]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.5596e-06, 9.9963e-01, 3.6453e-04]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.7132e-06, 9.9990e-01, 9.4713e-05]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[2.3450e-06, 9.9998e-01, 1.5828e-05]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.2462e-06, 9.9996e-01, 3.7854e-05]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.8647e-06, 9.9998e-01, 1.7762e-05]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[3.5904e-06, 9.9999e-01, 5.5569e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[3.5647e-06, 9.9999e-01, 2.8092e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[2.2880e-06, 9.9997e-01, 2.5830e-05]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.9158e-06, 9.9993e-01, 6.4577e-05]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.6594e-06, 9.9999e-01, 8.4318e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.9706e-06, 1.0000e+00, 1.9686e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[8.9397e-07, 1.0000e+00, 7.4229e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[7.8803e-07, 1.0000e+00, 1.1767e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[2.5206e-06, 9.9998e-01, 1.5990e-05]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.7261e-06, 9.9998e-01, 5.3239e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[4.4800e-06, 9.9999e-01, 7.2560e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[2.3388e-06, 1.0000e+00, 4.5595e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.9496e-06, 1.0000e+00, 3.1092e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.7218e-06, 1.0000e+00, 2.3520e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.3602e-06, 1.0000e+00, 4.3890e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.8557e-06, 1.0000e+00, 1.1539e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[5.0541e-06, 9.9999e-01, 5.3792e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.8083e-05, 9.9997e-01, 9.7942e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.0075e-05, 9.9999e-01, 3.4899e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[2.2734e-06, 1.0000e+00, 7.0771e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.4746e-06, 1.0000e+00, 3.9164e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.0134e-06, 1.0000e+00, 7.1465e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.0420e-06, 1.0000e+00, 1.8239e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.4314e-07, 1.0000e+00, 1.0375e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.5844e-06, 1.0000e+00, 9.3004e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[2.1586e-06, 1.0000e+00, 9.3773e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[2.0660e-06, 1.0000e+00, 8.4508e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.9692e-06, 1.0000e+00, 7.5383e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[2.2013e-06, 1.0000e+00, 7.8007e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.7534e-06, 1.0000e+00, 5.1947e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.6743e-06, 1.0000e+00, 4.1450e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[2.6250e-06, 1.0000e+00, 5.7344e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[3.6851e-06, 1.0000e+00, 7.1815e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[2.6401e-06, 1.0000e+00, 1.3349e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.8891e-06, 1.0000e+00, 2.9231e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[3.9258e-06, 9.9999e-01, 7.0940e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.8050e-05, 9.9997e-01, 1.4536e-05]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.1247e-05, 9.9997e-01, 1.9512e-05]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[3.2831e-06, 9.9998e-01, 1.5956e-05]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[2.1170e-06, 9.9999e-01, 1.1295e-05]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[3.1851e-06, 9.9996e-01, 4.0181e-05]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.1168e-05, 9.9964e-01, 3.4501e-04]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[6.7874e-06, 9.9992e-01, 7.4587e-05]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[5.9151e-06, 9.9997e-01, 2.7048e-05]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[2.7422e-06, 9.9999e-01, 7.1977e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[3.1287e-06, 9.9998e-01, 1.3433e-05]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[7.0012e-06, 9.9985e-01, 1.4423e-04]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[8.6313e-05, 9.9738e-01, 2.5373e-03]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[2.0227e-05, 9.9962e-01, 3.5644e-04]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[2.9877e-06, 9.9999e-01, 1.0614e-05]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[2.4770e-06, 9.9999e-01, 5.8937e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.9281e-06, 1.0000e+00, 1.9935e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.5720e-06, 1.0000e+00, 9.0208e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.5068e-06, 1.0000e+00, 1.6276e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.4962e-06, 9.9999e-01, 7.3981e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[4.5682e-06, 9.9995e-01, 4.7993e-05]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[5.1721e-06, 9.9998e-01, 1.1486e-05]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[2.7162e-06, 1.0000e+00, 1.8111e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.7780e-06, 1.0000e+00, 4.5306e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.6123e-06, 1.0000e+00, 3.1206e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.5704e-06, 1.0000e+00, 2.5774e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.6937e-06, 1.0000e+00, 3.1668e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[2.1009e-06, 1.0000e+00, 7.8581e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[3.2041e-06, 1.0000e+00, 1.4884e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[2.7415e-06, 1.0000e+00, 1.2749e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[2.2221e-06, 1.0000e+00, 8.2922e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.8356e-06, 1.0000e+00, 1.3998e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.8522e-06, 1.0000e+00, 1.3416e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.6996e-06, 1.0000e+00, 1.9328e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[2.4975e-06, 9.9999e-01, 2.8738e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[3.9205e-06, 9.9999e-01, 6.5478e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[5.9580e-06, 9.9998e-01, 9.0064e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[2.2914e-06, 1.0000e+00, 8.0544e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.7031e-06, 1.0000e+00, 2.8711e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.3976e-06, 1.0000e+00, 2.6347e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.2608e-06, 1.0000e+00, 3.3307e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.2583e-06, 1.0000e+00, 3.4400e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.4683e-06, 1.0000e+00, 3.7750e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.5886e-06, 1.0000e+00, 6.0356e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[2.1640e-06, 1.0000e+00, 1.0703e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[3.0501e-06, 9.9999e-01, 1.9384e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[4.1223e-06, 9.9999e-01, 3.2007e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[3.0046e-06, 9.9999e-01, 2.0456e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.6838e-06, 1.0000e+00, 6.3088e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.3821e-06, 1.0000e+00, 4.4596e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.2487e-06, 1.0000e+00, 2.7366e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.1641e-06, 1.0000e+00, 2.3059e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.1775e-06, 1.0000e+00, 2.3646e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.2642e-06, 1.0000e+00, 2.9703e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.5305e-06, 1.0000e+00, 6.1080e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.9037e-06, 1.0000e+00, 1.5778e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.7123e-06, 1.0000e+00, 1.1874e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.4315e-06, 1.0000e+00, 4.3260e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.4076e-06, 1.0000e+00, 2.3914e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.3740e-06, 1.0000e+00, 1.9937e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.4390e-06, 1.0000e+00, 2.3632e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.5426e-06, 1.0000e+00, 4.2668e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.7433e-06, 1.0000e+00, 1.1107e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[2.2803e-06, 9.9999e-01, 2.8760e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[4.6610e-06, 9.9999e-01, 3.8316e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.0583e-05, 9.9998e-01, 5.5996e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[6.4291e-06, 9.9999e-01, 5.2238e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[2.9072e-06, 9.9999e-01, 3.0193e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[3.8621e-06, 9.9999e-01, 8.5604e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[6.7034e-06, 9.9996e-01, 2.9251e-05]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[4.2715e-06, 9.9998e-01, 1.3835e-05]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.4982e-06, 1.0000e+00, 1.2502e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.1653e-06, 1.0000e+00, 2.8733e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.6677e-07, 1.0000e+00, 1.6214e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[8.5409e-07, 1.0000e+00, 1.4699e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[7.8624e-07, 1.0000e+00, 1.7238e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[7.8465e-07, 1.0000e+00, 3.9087e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[8.2925e-07, 1.0000e+00, 1.3126e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.1852e-06, 9.9999e-01, 8.2071e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.0482e-06, 9.9999e-01, 4.5869e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.0380e-06, 9.9999e-01, 5.9323e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.1983e-06, 9.9999e-01, 6.5804e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.1132e-06, 1.0000e+00, 1.0863e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.1801e-06, 1.0000e+00, 3.8351e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.1653e-06, 1.0000e+00, 2.5459e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.0741e-06, 1.0000e+00, 2.9246e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9360e-07, 1.0000e+00, 3.6526e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.1146e-06, 1.0000e+00, 6.4595e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.7642e-06, 1.0000e+00, 2.5626e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[2.1103e-06, 1.0000e+00, 2.8123e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.6723e-06, 1.0000e+00, 1.0705e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.3249e-06, 1.0000e+00, 3.9410e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.1497e-06, 1.0000e+00, 3.2804e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9520e-07, 1.0000e+00, 3.4561e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.7157e-07, 1.0000e+00, 3.9107e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.0887e-06, 1.0000e+00, 4.8950e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.2518e-06, 1.0000e+00, 5.4578e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.4621e-06, 1.0000e+00, 5.2980e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.4688e-06, 1.0000e+00, 5.0257e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.2555e-06, 1.0000e+00, 4.4828e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9223e-07, 1.0000e+00, 4.3531e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[7.9249e-07, 1.0000e+00, 5.0384e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[7.9354e-07, 1.0000e+00, 5.5693e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[8.5034e-07, 1.0000e+00, 5.5662e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[8.6223e-07, 1.0000e+00, 4.3340e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.0634e-07, 1.0000e+00, 3.6154e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.1977e-07, 1.0000e+00, 4.0733e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[8.6308e-07, 1.0000e+00, 8.9366e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.6011e-06, 1.0000e+00, 3.1948e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[3.2378e-06, 9.9999e-01, 8.8250e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[7.5807e-06, 9.9996e-01, 2.9678e-05]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.0194e-05, 9.9992e-01, 6.5505e-05]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.2783e-05, 9.9985e-01, 1.3463e-04]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[4.8345e-05, 9.9854e-01, 1.4075e-03]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[4.0799e-04, 9.5023e-01, 4.9366e-02]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0011, 0.7976, 0.2013]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0021, 0.7700, 0.2279]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[2.4233e-04, 9.9833e-01, 1.4323e-03]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[2.7762e-05, 9.9994e-01, 3.1417e-05]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[6.6340e-06, 9.9999e-01, 3.3269e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[5.2887e-06, 9.9999e-01, 1.7205e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[6.4204e-06, 9.9999e-01, 2.2742e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[7.5490e-06, 9.9999e-01, 3.2457e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[6.5561e-06, 9.9999e-01, 2.7670e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[5.1149e-06, 9.9999e-01, 1.8829e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[4.0843e-06, 9.9999e-01, 1.1893e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[3.6353e-06, 1.0000e+00, 1.0076e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[4.1038e-06, 9.9999e-01, 1.1919e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[4.8202e-06, 9.9999e-01, 1.3237e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[4.4154e-06, 9.9999e-01, 1.0853e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[3.6529e-06, 1.0000e+00, 7.2449e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[2.7122e-06, 1.0000e+00, 4.6222e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[2.5019e-06, 1.0000e+00, 5.4302e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[2.7593e-06, 1.0000e+00, 7.0454e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[3.5665e-06, 1.0000e+00, 1.1499e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[7.6415e-06, 9.9999e-01, 4.3250e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[2.0747e-05, 9.9996e-01, 2.1076e-05]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[4.7650e-05, 9.9990e-01, 5.0535e-05]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[2.2877e-05, 9.9996e-01, 1.6177e-05]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[5.1723e-06, 9.9999e-01, 1.6958e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[2.8683e-06, 1.0000e+00, 7.0502e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[2.0735e-06, 1.0000e+00, 8.5367e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.9674e-06, 1.0000e+00, 1.6249e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[2.2279e-06, 1.0000e+00, 2.3630e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[2.3455e-06, 1.0000e+00, 2.0692e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[2.0992e-06, 1.0000e+00, 1.1771e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.6672e-06, 1.0000e+00, 6.5583e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.5060e-06, 1.0000e+00, 5.5430e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.6070e-06, 1.0000e+00, 7.6280e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[2.3905e-06, 1.0000e+00, 1.3967e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[3.6456e-06, 9.9999e-01, 1.5472e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[4.9543e-06, 9.9999e-01, 1.4853e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[4.8536e-06, 9.9999e-01, 1.1379e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[3.3551e-06, 1.0000e+00, 6.8221e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[2.2473e-06, 1.0000e+00, 4.5443e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.8920e-06, 1.0000e+00, 5.3366e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.7460e-06, 1.0000e+00, 6.4795e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.8006e-06, 1.0000e+00, 6.8223e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.8539e-06, 1.0000e+00, 6.0551e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.9788e-06, 1.0000e+00, 5.6708e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[2.2857e-06, 1.0000e+00, 7.1399e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[2.7534e-06, 1.0000e+00, 1.4766e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[4.0548e-06, 9.9999e-01, 5.9550e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[4.8040e-06, 9.9998e-01, 1.2455e-05]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[3.9505e-06, 9.9999e-01, 7.2541e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.9397e-06, 1.0000e+00, 1.4054e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.6025e-06, 1.0000e+00, 6.1413e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.5992e-06, 1.0000e+00, 4.6103e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.7057e-06, 1.0000e+00, 6.0384e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[2.2539e-06, 1.0000e+00, 8.7300e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[3.4141e-06, 1.0000e+00, 1.2950e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[2.7840e-06, 1.0000e+00, 1.3538e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.7442e-06, 1.0000e+00, 5.6367e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.3807e-06, 1.0000e+00, 3.4132e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.3785e-06, 1.0000e+00, 3.2336e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.6154e-06, 1.0000e+00, 3.9095e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[2.3609e-06, 1.0000e+00, 7.1809e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[5.2364e-06, 9.9999e-01, 3.5311e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.5025e-05, 9.9996e-01, 2.6130e-05]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.1028e-05, 9.9996e-01, 3.1007e-05]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[8.9402e-06, 9.9997e-01, 1.6870e-05]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[7.7338e-06, 9.9998e-01, 1.6735e-05]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[5.9754e-06, 9.9998e-01, 1.1173e-05]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[3.5043e-06, 9.9999e-01, 3.1022e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[2.0287e-06, 1.0000e+00, 8.1439e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.7261e-06, 1.0000e+00, 5.2250e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.6295e-06, 1.0000e+00, 4.4039e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.8074e-06, 1.0000e+00, 5.0630e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[2.5942e-06, 1.0000e+00, 1.1190e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[4.3574e-06, 9.9999e-01, 2.0973e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[2.9188e-06, 1.0000e+00, 1.1429e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.7350e-06, 1.0000e+00, 3.8377e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.4036e-06, 1.0000e+00, 2.7724e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.1987e-06, 1.0000e+00, 3.1144e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.2590e-06, 1.0000e+00, 3.6670e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.4199e-06, 1.0000e+00, 4.3218e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.5710e-06, 1.0000e+00, 4.8311e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.5222e-06, 1.0000e+00, 4.1927e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.4889e-06, 1.0000e+00, 3.3891e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.6122e-06, 1.0000e+00, 3.4008e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.6450e-06, 1.0000e+00, 3.7262e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.5094e-06, 1.0000e+00, 4.1217e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.4278e-06, 1.0000e+00, 5.0150e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.5057e-06, 1.0000e+00, 8.2411e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.5725e-06, 1.0000e+00, 1.0742e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.5313e-06, 1.0000e+00, 8.9230e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.5509e-06, 1.0000e+00, 6.2812e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.6628e-06, 1.0000e+00, 6.6671e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[2.1713e-06, 1.0000e+00, 9.3693e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[3.3015e-06, 9.9999e-01, 2.5001e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[4.5270e-06, 9.9999e-01, 8.1870e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.3583e-06, 9.9996e-01, 2.7826e-05]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.6168e-05, 9.9995e-01, 3.3270e-05]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.5882e-05, 9.9997e-01, 1.4461e-05]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.1143e-05, 9.9998e-01, 7.4719e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[3.0494e-06, 9.9999e-01, 2.0039e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[2.3388e-06, 1.0000e+00, 5.0964e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[2.1454e-06, 1.0000e+00, 3.7870e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.9480e-06, 1.0000e+00, 3.1919e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.6320e-06, 1.0000e+00, 3.0519e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.4340e-06, 1.0000e+00, 3.1973e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.4319e-06, 1.0000e+00, 4.6915e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.6541e-06, 1.0000e+00, 1.2513e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[3.1654e-06, 9.9999e-01, 5.3135e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[3.1933e-05, 9.9982e-01, 1.4490e-04]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[8.6974e-05, 9.9898e-01, 9.3798e-04]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.8164e-05, 9.9989e-01, 9.0317e-05]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[4.4800e-06, 9.9999e-01, 5.1556e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[2.9390e-06, 1.0000e+00, 1.8461e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.9091e-06, 1.0000e+00, 1.5396e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.6527e-06, 1.0000e+00, 2.3573e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[2.2239e-06, 1.0000e+00, 1.8435e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[2.8373e-06, 1.0000e+00, 1.6908e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[2.5604e-06, 1.0000e+00, 1.9175e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.5657e-06, 1.0000e+00, 1.2463e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.2449e-06, 1.0000e+00, 8.6129e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.2128e-06, 1.0000e+00, 8.4411e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.3128e-06, 1.0000e+00, 8.7839e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.1364e-06, 1.0000e+00, 5.6927e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.0645e-06, 1.0000e+00, 4.1212e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.2071e-06, 1.0000e+00, 4.2526e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.0765e-06, 1.0000e+00, 4.8540e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.7037e-06, 1.0000e+00, 1.3722e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[2.7888e-06, 9.9999e-01, 5.0162e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[2.5584e-06, 9.9999e-01, 9.0118e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[2.2706e-06, 9.9999e-01, 4.9135e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[4.3908e-06, 9.9998e-01, 1.4970e-05]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[2.7146e-06, 9.9999e-01, 3.6880e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[2.2889e-06, 1.0000e+00, 1.4663e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[2.0683e-06, 1.0000e+00, 1.4941e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[2.5980e-06, 1.0000e+00, 1.9477e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[3.4708e-06, 9.9999e-01, 2.2382e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[4.5026e-06, 9.9999e-01, 3.0010e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[4.6346e-06, 9.9999e-01, 3.6830e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[3.4931e-06, 9.9999e-01, 2.7085e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[2.4719e-06, 1.0000e+00, 1.6222e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.9042e-06, 1.0000e+00, 1.9189e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[2.2391e-06, 9.9999e-01, 3.4481e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[3.4712e-06, 9.9999e-01, 5.7049e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[3.7021e-06, 9.9999e-01, 4.5280e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[3.0557e-06, 9.9999e-01, 2.5289e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[2.6908e-06, 1.0000e+00, 1.8309e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[3.1000e-06, 9.9999e-01, 2.2273e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[4.3576e-06, 9.9999e-01, 3.7425e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[5.7369e-06, 9.9999e-01, 5.7855e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[5.0903e-06, 9.9999e-01, 5.9704e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[3.9796e-06, 9.9999e-01, 3.2065e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[3.4732e-06, 9.9999e-01, 2.5400e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[4.7175e-06, 9.9999e-01, 6.2287e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-e24652922605>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mgenerate_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_train_X0\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mreal_train_Y_labels0\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mpadding_mask0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_seed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreal_train_X0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;31m# generate_dataset(real_train_X1 ,real_train_Y_labels1 ,padding_mask1,n_seed=n_seed,n_samples=real_train_X1.size(0),max_length=max_length)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# generate_dataset(real_train_X2 ,real_train_Y_labels2 ,padding_mask2,n_seed=n_seed,n_samples=real_train_X2.size(0),max_length=max_length)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-787b8d7feb39>\u001b[0m in \u001b[0;36mgenerate_dataset\u001b[0;34m(X, Y, masks, n_seed, n_samples, max_length)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mn_seed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# Loop until 400 timesteps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0msrc_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_square_subsequent_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0mY_predicted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maux_predicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatapoint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msrc_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m             \u001b[0mY_predicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY_predicted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mone_new_timestep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mY_predicted\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-f6de22771188>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, src_mask, padding_mask)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInputLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0md_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpositional_encoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpadding_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0moutput1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutputLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, mask, src_key_padding_mask)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmod\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_key_padding_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msrc_key_padding_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, src_mask, src_key_padding_mask)\u001b[0m\n\u001b[1;32m    292\u001b[0m         \"\"\"\n\u001b[1;32m    293\u001b[0m         src2 = self.self_attn(src, src, src, attn_mask=src_mask,\n\u001b[0;32m--> 294\u001b[0;31m                               key_padding_mask=src_key_padding_mask)[0]\n\u001b[0m\u001b[1;32m    295\u001b[0m         \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msrc\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/activation.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask)\u001b[0m\n\u001b[1;32m    985\u001b[0m                 \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    986\u001b[0m                 \u001b[0mkey_padding_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey_padding_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneed_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mneed_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 987\u001b[0;31m                 attn_mask=attn_mask)\n\u001b[0m\u001b[1;32m    988\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmulti_head_attention_forward\u001b[0;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v)\u001b[0m\n\u001b[1;32m   4634\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4635\u001b[0m             \u001b[0;31m# self-attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4636\u001b[0;31m             \u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_proj_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_proj_bias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4638\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1751\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1753\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1754\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "real_train_X0 ,real_train_Y_labels0 ,padding_mask0= get_one_class(real_train_X ,real_train_Y_labels ,padding_mask,0)\n",
    "real_train_X1 ,real_train_Y_labels1 ,padding_mask1= get_one_class(real_train_X ,real_train_Y_labels ,padding_mask,1)\n",
    "real_train_X2 ,real_train_Y_labels2 ,padding_mask2= get_one_class(real_train_X ,real_train_Y_labels ,padding_mask,2)\n",
    "real_train_X3 ,real_train_Y_labels3 ,padding_mask3= get_one_class(real_train_X ,real_train_Y_labels ,padding_mask,3)\n",
    "\n",
    "\n",
    "generate_dataset(real_train_X0 ,real_train_Y_labels0 ,padding_mask0,n_seed=n_seed,n_samples=real_train_X0.size(0),max_length=max_length)\n",
    "generate_dataset(real_train_X1 ,real_train_Y_labels1 ,padding_mask1,n_seed=n_seed,n_samples=real_train_X1.size(0),max_length=max_length)\n",
    "generate_dataset(real_train_X2 ,real_train_Y_labels2 ,padding_mask2,n_seed=n_seed,n_samples=real_train_X2.size(0),max_length=max_length)\n",
    "generate_dataset(real_train_X3 ,real_train_Y_labels3 ,padding_mask3,n_seed=n_seed,n_samples=real_train_X3.size(0),max_length=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3193017c-1930-4e3e-bdaa-29a9fcb36697",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('npz_transformer_token_V7',X=generated_dataset_X,masks= resulted_masks,Y=generated_dataset_Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "37c638b2-11d3-4bd1-a128-1a225e530077",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74, None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect(),torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092d6dec-bdbb-4961-956c-28eb2390b470",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# What is the average values of all samples in variable length sequence\n",
    "\n",
    "mean_of_samples = []\n",
    "for x,length in zip(real_train_X, real_train_lengths):\n",
    "    mean_of_samples.append(torch.sum(x)/(9*length)) # torch.Size([2500])\n",
    "    \n",
    "print(np.mean(mean_of_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235e2e56-6e32-4d9c-b04f-d0eb8356742b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.max(input)  Tensor\n",
    "# Returns the maximum value of all elements in the input tensor.\n",
    "\n",
    "torch.max(real_train_X.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71072b7-4b93-41d4-9894-c81bd6686485",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.min(real_train_X.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0674c9-e124-4dd3-99be-e7dc8ca16a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(real_train_X.flatten(), 'o', color='black');\n",
    "plt.xscale(\"log\")\n",
    "ax.set_title('CDF - Class all')\n",
    "ax.set_xlabel('The Sequence Length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c8cf9d-b707-430d-bf46-1f13e24d8242",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.mean(real_train_X,2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8134539e-d658-4fa6-87f0-f75d99814867",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(torch.mean(real_train_X,2).flatten(), 'o', color='black');\n",
    "plt.xscale(\"log\")\n",
    "ax.set_title('CDF - Class all')\n",
    "ax.set_xlabel('The Sequence Length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6aa925-a487-46f4-b536-4cb11877f3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist([1,1,1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114d43f4-af58-47d6-abdb-bdb7c4e3c1b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
