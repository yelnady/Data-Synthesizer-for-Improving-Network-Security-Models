{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cutting-lottery",
   "metadata": {},
   "source": [
    "# Required Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "significant-blanket",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import sys, random, math, pickle\n",
    "from time import time\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import MSELoss\n",
    "import seaborn as sns\n",
    "from tensorboard import default\n",
    "import torch.nn.functional as F\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "sys.path.append('DG/gan')\n",
    "import gc\n",
    "print(device)\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "curious-district",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total    : 50962169856\n",
      "free     : 50958106624\n",
      "used     : 4063232\n"
     ]
    }
   ],
   "source": [
    "from pynvml import *\n",
    "nvmlInit()\n",
    "h = nvmlDeviceGetHandleByIndex(1)\n",
    "info = nvmlDeviceGetMemoryInfo(h)\n",
    "print(f'total    : {info.total}')\n",
    "print(f'free     : {info.free}')\n",
    "print(f'used     : {info.used}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expected-senator",
   "metadata": {},
   "source": [
    "# Import Real Training Data to Generate New Data from it.\n",
    "\n",
    "### Actual Distribution\n",
    "- Class0: 6250\n",
    "- Class1: 16124\n",
    "- Class2: 21273\n",
    "- Class3: 5278"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "unique-burden",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_one_class(X,Y,mask,class_label): # (X, Y, and mask) are the whole dataset that is consisted of many classes, Y is NOT One-Hot Encoded\n",
    "    indices_class_label = np.where(Y==class_label)\n",
    "    X,Y,mask = X[indices_class_label], Y[indices_class_label], mask[indices_class_label] \n",
    "    indices_non_zero = torch.nonzero(torch.sum(mask,1)-1).squeeze()\n",
    "    return X[indices_non_zero], Y[indices_non_zero], mask[indices_non_zero]\n",
    "\n",
    "def get_n_samples(X,n_samples):\n",
    "    randomList = random.sample(range(0, X.shape[0]), n_samples)\n",
    "    return X[randomList]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "considered-discharge",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_real = np.load('../data/web/data_train.npz')\n",
    "\n",
    "real_train_X = torch.from_numpy(training_real['data_feature']).float() #[50000, 2500, 9]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "laden-impression",
   "metadata": {},
   "source": [
    "# PyTorch Transformer Model\n",
    "\n",
    "- Later, we need to remove this from here and put in a separate folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "greek-review",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "included-physics",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TimeSeriesTransformer(nn.Module):\n",
    "\n",
    "    def __init__(self, n_features=1, d_model=256, n_heads=8, n_hidden=256, n_layers=6, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.model_type = 'Time Series Transformer Model'\n",
    "        self.InputLinear = nn.Linear(n_features, d_model)\n",
    "        \n",
    "        self.positional_encoding = PositionalEncoding(d_model, dropout)\n",
    "        encoder_layers = TransformerEncoderLayer(d_model, n_heads, n_hidden, dropout)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layers, n_layers)\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.n_features = n_features\n",
    "        \n",
    "        self.OutputLinear = nn.Linear(d_model, n_features) # The output of the encoder is similar to the input of the encoder, both are (B,S,d_model)\n",
    "\n",
    "        self.init_weights()\n",
    "        self.activation = nn.Tanh()\n",
    "            \n",
    "\n",
    "    def generate_square_subsequent_mask(self, sz):\n",
    "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "        mask = mask.float().masked_fill(mask == 0, float(-1e6)).masked_fill(mask == 1, float(0.0))\n",
    "        return mask.to(device)\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        self.InputLinear.weight.data.uniform_(-initrange, initrange)\n",
    "        self.OutputLinear.bias.data.zero_()\n",
    "        self.OutputLinear.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, src, src_mask,padding_mask):\n",
    "        src = self.InputLinear(src) * math.sqrt(self.d_model)\n",
    "        src = self.positional_encoding(src)\n",
    "        output = self.transformer_encoder(src, src_mask,padding_mask)\n",
    "        output = self.OutputLinear(output)\n",
    "        output = self.activation(output) # output[...,:9] --> Actual 9 values\n",
    "        return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "laughing-naples",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeSeriesTransformer(\n",
       "  (InputLinear): Linear(in_features=1, out_features=256, bias=True)\n",
       "  (positional_encoding): PositionalEncoding(\n",
       "    (dropout): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       "  (transformer_encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.2, inplace=False)\n",
       "        (dropout2): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (1): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.2, inplace=False)\n",
       "        (dropout2): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (2): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.2, inplace=False)\n",
       "        (dropout2): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (3): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.2, inplace=False)\n",
       "        (dropout2): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (4): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.2, inplace=False)\n",
       "        (dropout2): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (5): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.2, inplace=False)\n",
       "        (dropout2): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (OutputLinear): Linear(in_features=256, out_features=1, bias=True)\n",
       "  (activation): Tanh()\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model = TimeSeriesTransformer().to(device)\n",
    "\n",
    "model.load_state_dict(torch.load('WWT_weights_new'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "herbal-madness",
   "metadata": {},
   "source": [
    "# Generating New Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "reliable-finland",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All generated Data has at least three timesteps because the seed is 2\n",
    "\n",
    "# We should stop at 2 or at least if S >= datapoint_len "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "driving-frontier",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 1])\n",
      "torch.Size([3, 1, 1])\n",
      "torch.Size([4, 1, 1])\n",
      "torch.Size([5, 1, 1])\n",
      "torch.Size([6, 1, 1])\n",
      "torch.Size([7, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([9, 1, 1])\n",
      "torch.Size([10, 1, 1])\n",
      "torch.Size([11, 1, 1])\n",
      "torch.Size([12, 1, 1])\n",
      "torch.Size([13, 1, 1])\n",
      "torch.Size([14, 1, 1])\n",
      "torch.Size([15, 1, 1])\n",
      "torch.Size([16, 1, 1])\n",
      "torch.Size([17, 1, 1])\n",
      "torch.Size([18, 1, 1])\n",
      "torch.Size([19, 1, 1])\n",
      "torch.Size([20, 1, 1])\n",
      "torch.Size([21, 1, 1])\n",
      "torch.Size([22, 1, 1])\n",
      "torch.Size([23, 1, 1])\n",
      "torch.Size([24, 1, 1])\n",
      "torch.Size([25, 1, 1])\n",
      "torch.Size([26, 1, 1])\n",
      "torch.Size([27, 1, 1])\n",
      "torch.Size([28, 1, 1])\n",
      "torch.Size([29, 1, 1])\n",
      "torch.Size([30, 1, 1])\n",
      "torch.Size([31, 1, 1])\n",
      "torch.Size([32, 1, 1])\n",
      "torch.Size([33, 1, 1])\n",
      "torch.Size([34, 1, 1])\n",
      "torch.Size([35, 1, 1])\n",
      "torch.Size([36, 1, 1])\n",
      "torch.Size([37, 1, 1])\n",
      "torch.Size([38, 1, 1])\n",
      "torch.Size([39, 1, 1])\n",
      "torch.Size([40, 1, 1])\n",
      "torch.Size([41, 1, 1])\n",
      "torch.Size([42, 1, 1])\n",
      "torch.Size([43, 1, 1])\n",
      "torch.Size([44, 1, 1])\n",
      "torch.Size([45, 1, 1])\n",
      "torch.Size([46, 1, 1])\n",
      "torch.Size([47, 1, 1])\n",
      "torch.Size([48, 1, 1])\n",
      "torch.Size([49, 1, 1])\n",
      "torch.Size([50, 1, 1])\n",
      "torch.Size([51, 1, 1])\n",
      "torch.Size([52, 1, 1])\n",
      "torch.Size([53, 1, 1])\n",
      "torch.Size([54, 1, 1])\n",
      "torch.Size([55, 1, 1])\n",
      "torch.Size([56, 1, 1])\n",
      "torch.Size([57, 1, 1])\n",
      "torch.Size([58, 1, 1])\n",
      "torch.Size([59, 1, 1])\n",
      "torch.Size([60, 1, 1])\n",
      "torch.Size([61, 1, 1])\n",
      "torch.Size([62, 1, 1])\n",
      "torch.Size([63, 1, 1])\n",
      "torch.Size([64, 1, 1])\n",
      "torch.Size([65, 1, 1])\n",
      "torch.Size([66, 1, 1])\n",
      "torch.Size([67, 1, 1])\n",
      "torch.Size([68, 1, 1])\n",
      "torch.Size([69, 1, 1])\n",
      "torch.Size([70, 1, 1])\n",
      "torch.Size([71, 1, 1])\n",
      "torch.Size([72, 1, 1])\n",
      "torch.Size([73, 1, 1])\n",
      "torch.Size([74, 1, 1])\n",
      "torch.Size([75, 1, 1])\n",
      "torch.Size([76, 1, 1])\n",
      "torch.Size([77, 1, 1])\n",
      "torch.Size([78, 1, 1])\n",
      "torch.Size([79, 1, 1])\n",
      "torch.Size([80, 1, 1])\n",
      "torch.Size([81, 1, 1])\n",
      "torch.Size([82, 1, 1])\n",
      "torch.Size([83, 1, 1])\n",
      "torch.Size([84, 1, 1])\n",
      "torch.Size([85, 1, 1])\n",
      "torch.Size([86, 1, 1])\n",
      "torch.Size([87, 1, 1])\n",
      "torch.Size([88, 1, 1])\n",
      "torch.Size([89, 1, 1])\n",
      "torch.Size([90, 1, 1])\n",
      "torch.Size([91, 1, 1])\n",
      "torch.Size([92, 1, 1])\n",
      "torch.Size([93, 1, 1])\n",
      "torch.Size([94, 1, 1])\n",
      "torch.Size([95, 1, 1])\n",
      "torch.Size([96, 1, 1])\n",
      "torch.Size([97, 1, 1])\n",
      "torch.Size([98, 1, 1])\n",
      "torch.Size([99, 1, 1])\n",
      "torch.Size([100, 1, 1])\n",
      "torch.Size([101, 1, 1])\n",
      "torch.Size([102, 1, 1])\n",
      "torch.Size([103, 1, 1])\n",
      "torch.Size([104, 1, 1])\n",
      "torch.Size([105, 1, 1])\n",
      "torch.Size([106, 1, 1])\n",
      "torch.Size([107, 1, 1])\n",
      "torch.Size([108, 1, 1])\n",
      "torch.Size([109, 1, 1])\n",
      "torch.Size([110, 1, 1])\n",
      "torch.Size([111, 1, 1])\n",
      "torch.Size([112, 1, 1])\n",
      "torch.Size([113, 1, 1])\n",
      "torch.Size([114, 1, 1])\n",
      "torch.Size([115, 1, 1])\n",
      "torch.Size([116, 1, 1])\n",
      "torch.Size([117, 1, 1])\n",
      "torch.Size([118, 1, 1])\n",
      "torch.Size([119, 1, 1])\n",
      "torch.Size([120, 1, 1])\n",
      "torch.Size([121, 1, 1])\n",
      "torch.Size([122, 1, 1])\n",
      "torch.Size([123, 1, 1])\n",
      "torch.Size([124, 1, 1])\n",
      "torch.Size([125, 1, 1])\n",
      "torch.Size([126, 1, 1])\n",
      "torch.Size([127, 1, 1])\n",
      "torch.Size([128, 1, 1])\n",
      "torch.Size([129, 1, 1])\n",
      "torch.Size([130, 1, 1])\n",
      "torch.Size([131, 1, 1])\n",
      "torch.Size([132, 1, 1])\n",
      "torch.Size([133, 1, 1])\n",
      "torch.Size([134, 1, 1])\n",
      "torch.Size([135, 1, 1])\n",
      "torch.Size([136, 1, 1])\n",
      "torch.Size([137, 1, 1])\n",
      "torch.Size([138, 1, 1])\n",
      "torch.Size([139, 1, 1])\n",
      "torch.Size([140, 1, 1])\n",
      "torch.Size([141, 1, 1])\n",
      "torch.Size([142, 1, 1])\n",
      "torch.Size([143, 1, 1])\n",
      "torch.Size([144, 1, 1])\n",
      "torch.Size([145, 1, 1])\n",
      "torch.Size([146, 1, 1])\n",
      "torch.Size([147, 1, 1])\n",
      "torch.Size([148, 1, 1])\n",
      "torch.Size([149, 1, 1])\n",
      "torch.Size([150, 1, 1])\n",
      "torch.Size([151, 1, 1])\n",
      "torch.Size([152, 1, 1])\n",
      "torch.Size([153, 1, 1])\n",
      "torch.Size([154, 1, 1])\n",
      "torch.Size([155, 1, 1])\n",
      "torch.Size([156, 1, 1])\n",
      "torch.Size([157, 1, 1])\n",
      "torch.Size([158, 1, 1])\n",
      "torch.Size([159, 1, 1])\n",
      "torch.Size([160, 1, 1])\n",
      "torch.Size([161, 1, 1])\n",
      "torch.Size([162, 1, 1])\n",
      "torch.Size([163, 1, 1])\n",
      "torch.Size([164, 1, 1])\n",
      "torch.Size([165, 1, 1])\n",
      "torch.Size([166, 1, 1])\n",
      "torch.Size([167, 1, 1])\n",
      "torch.Size([168, 1, 1])\n",
      "torch.Size([169, 1, 1])\n",
      "torch.Size([170, 1, 1])\n",
      "torch.Size([171, 1, 1])\n",
      "torch.Size([172, 1, 1])\n",
      "torch.Size([173, 1, 1])\n",
      "torch.Size([174, 1, 1])\n",
      "torch.Size([175, 1, 1])\n",
      "torch.Size([176, 1, 1])\n",
      "torch.Size([177, 1, 1])\n",
      "torch.Size([178, 1, 1])\n",
      "torch.Size([179, 1, 1])\n",
      "torch.Size([180, 1, 1])\n",
      "torch.Size([181, 1, 1])\n",
      "torch.Size([182, 1, 1])\n",
      "torch.Size([183, 1, 1])\n",
      "torch.Size([184, 1, 1])\n",
      "torch.Size([185, 1, 1])\n",
      "torch.Size([186, 1, 1])\n",
      "torch.Size([187, 1, 1])\n",
      "torch.Size([188, 1, 1])\n",
      "torch.Size([189, 1, 1])\n",
      "torch.Size([190, 1, 1])\n",
      "torch.Size([191, 1, 1])\n",
      "torch.Size([192, 1, 1])\n",
      "torch.Size([193, 1, 1])\n",
      "torch.Size([194, 1, 1])\n",
      "torch.Size([195, 1, 1])\n",
      "torch.Size([196, 1, 1])\n",
      "torch.Size([197, 1, 1])\n",
      "torch.Size([198, 1, 1])\n",
      "torch.Size([199, 1, 1])\n",
      "torch.Size([200, 1, 1])\n",
      "torch.Size([201, 1, 1])\n",
      "torch.Size([202, 1, 1])\n",
      "torch.Size([203, 1, 1])\n",
      "torch.Size([204, 1, 1])\n",
      "torch.Size([205, 1, 1])\n",
      "torch.Size([206, 1, 1])\n",
      "torch.Size([207, 1, 1])\n",
      "torch.Size([208, 1, 1])\n",
      "torch.Size([209, 1, 1])\n",
      "torch.Size([210, 1, 1])\n",
      "torch.Size([211, 1, 1])\n",
      "torch.Size([212, 1, 1])\n",
      "torch.Size([213, 1, 1])\n",
      "torch.Size([214, 1, 1])\n",
      "torch.Size([215, 1, 1])\n",
      "torch.Size([216, 1, 1])\n",
      "torch.Size([217, 1, 1])\n",
      "torch.Size([218, 1, 1])\n",
      "torch.Size([219, 1, 1])\n",
      "torch.Size([220, 1, 1])\n",
      "torch.Size([221, 1, 1])\n",
      "torch.Size([222, 1, 1])\n",
      "torch.Size([223, 1, 1])\n",
      "torch.Size([224, 1, 1])\n",
      "torch.Size([225, 1, 1])\n",
      "torch.Size([226, 1, 1])\n",
      "torch.Size([227, 1, 1])\n",
      "torch.Size([228, 1, 1])\n",
      "torch.Size([229, 1, 1])\n",
      "torch.Size([230, 1, 1])\n",
      "torch.Size([231, 1, 1])\n",
      "torch.Size([232, 1, 1])\n",
      "torch.Size([233, 1, 1])\n",
      "torch.Size([234, 1, 1])\n",
      "torch.Size([235, 1, 1])\n",
      "torch.Size([236, 1, 1])\n",
      "torch.Size([237, 1, 1])\n",
      "torch.Size([238, 1, 1])\n",
      "torch.Size([239, 1, 1])\n",
      "torch.Size([240, 1, 1])\n",
      "torch.Size([241, 1, 1])\n",
      "torch.Size([242, 1, 1])\n",
      "torch.Size([243, 1, 1])\n",
      "torch.Size([244, 1, 1])\n",
      "torch.Size([245, 1, 1])\n",
      "torch.Size([246, 1, 1])\n",
      "torch.Size([247, 1, 1])\n",
      "torch.Size([248, 1, 1])\n",
      "torch.Size([249, 1, 1])\n",
      "torch.Size([250, 1, 1])\n",
      "torch.Size([251, 1, 1])\n",
      "torch.Size([252, 1, 1])\n",
      "torch.Size([253, 1, 1])\n",
      "torch.Size([254, 1, 1])\n",
      "torch.Size([255, 1, 1])\n",
      "torch.Size([256, 1, 1])\n",
      "torch.Size([257, 1, 1])\n",
      "torch.Size([258, 1, 1])\n",
      "torch.Size([259, 1, 1])\n",
      "torch.Size([260, 1, 1])\n",
      "torch.Size([261, 1, 1])\n",
      "torch.Size([262, 1, 1])\n",
      "torch.Size([263, 1, 1])\n",
      "torch.Size([264, 1, 1])\n",
      "torch.Size([265, 1, 1])\n",
      "torch.Size([266, 1, 1])\n",
      "torch.Size([267, 1, 1])\n",
      "torch.Size([268, 1, 1])\n",
      "torch.Size([269, 1, 1])\n",
      "torch.Size([270, 1, 1])\n",
      "torch.Size([271, 1, 1])\n",
      "torch.Size([272, 1, 1])\n",
      "torch.Size([273, 1, 1])\n",
      "torch.Size([274, 1, 1])\n",
      "torch.Size([275, 1, 1])\n",
      "torch.Size([276, 1, 1])\n",
      "torch.Size([277, 1, 1])\n",
      "torch.Size([278, 1, 1])\n",
      "torch.Size([279, 1, 1])\n",
      "torch.Size([280, 1, 1])\n",
      "torch.Size([281, 1, 1])\n",
      "torch.Size([282, 1, 1])\n",
      "torch.Size([283, 1, 1])\n",
      "torch.Size([284, 1, 1])\n",
      "torch.Size([285, 1, 1])\n",
      "torch.Size([286, 1, 1])\n",
      "torch.Size([287, 1, 1])\n",
      "torch.Size([288, 1, 1])\n",
      "torch.Size([289, 1, 1])\n",
      "torch.Size([290, 1, 1])\n",
      "torch.Size([291, 1, 1])\n",
      "torch.Size([292, 1, 1])\n",
      "torch.Size([293, 1, 1])\n",
      "torch.Size([294, 1, 1])\n",
      "torch.Size([295, 1, 1])\n",
      "torch.Size([296, 1, 1])\n",
      "torch.Size([297, 1, 1])\n",
      "torch.Size([298, 1, 1])\n",
      "torch.Size([299, 1, 1])\n",
      "torch.Size([300, 1, 1])\n",
      "torch.Size([301, 1, 1])\n",
      "torch.Size([302, 1, 1])\n",
      "torch.Size([303, 1, 1])\n",
      "torch.Size([304, 1, 1])\n",
      "torch.Size([305, 1, 1])\n",
      "torch.Size([306, 1, 1])\n",
      "torch.Size([307, 1, 1])\n",
      "torch.Size([308, 1, 1])\n",
      "torch.Size([309, 1, 1])\n",
      "torch.Size([310, 1, 1])\n",
      "torch.Size([311, 1, 1])\n",
      "torch.Size([312, 1, 1])\n",
      "torch.Size([313, 1, 1])\n",
      "torch.Size([314, 1, 1])\n",
      "torch.Size([315, 1, 1])\n",
      "torch.Size([316, 1, 1])\n",
      "torch.Size([317, 1, 1])\n",
      "torch.Size([318, 1, 1])\n",
      "torch.Size([319, 1, 1])\n",
      "torch.Size([320, 1, 1])\n",
      "torch.Size([321, 1, 1])\n",
      "torch.Size([322, 1, 1])\n",
      "torch.Size([323, 1, 1])\n",
      "torch.Size([324, 1, 1])\n",
      "torch.Size([325, 1, 1])\n",
      "torch.Size([326, 1, 1])\n",
      "torch.Size([327, 1, 1])\n",
      "torch.Size([328, 1, 1])\n",
      "torch.Size([329, 1, 1])\n",
      "torch.Size([330, 1, 1])\n",
      "torch.Size([331, 1, 1])\n",
      "torch.Size([332, 1, 1])\n",
      "torch.Size([333, 1, 1])\n",
      "torch.Size([334, 1, 1])\n",
      "torch.Size([335, 1, 1])\n",
      "torch.Size([336, 1, 1])\n",
      "torch.Size([337, 1, 1])\n",
      "torch.Size([338, 1, 1])\n",
      "torch.Size([339, 1, 1])\n",
      "torch.Size([340, 1, 1])\n",
      "torch.Size([341, 1, 1])\n",
      "torch.Size([342, 1, 1])\n",
      "torch.Size([343, 1, 1])\n",
      "torch.Size([344, 1, 1])\n",
      "torch.Size([345, 1, 1])\n",
      "torch.Size([346, 1, 1])\n",
      "torch.Size([347, 1, 1])\n",
      "torch.Size([348, 1, 1])\n",
      "torch.Size([349, 1, 1])\n",
      "torch.Size([350, 1, 1])\n",
      "torch.Size([351, 1, 1])\n",
      "torch.Size([352, 1, 1])\n",
      "torch.Size([353, 1, 1])\n",
      "torch.Size([354, 1, 1])\n",
      "torch.Size([355, 1, 1])\n",
      "torch.Size([356, 1, 1])\n",
      "torch.Size([357, 1, 1])\n",
      "torch.Size([358, 1, 1])\n",
      "torch.Size([359, 1, 1])\n",
      "torch.Size([360, 1, 1])\n",
      "torch.Size([361, 1, 1])\n",
      "torch.Size([362, 1, 1])\n",
      "torch.Size([363, 1, 1])\n",
      "torch.Size([364, 1, 1])\n",
      "torch.Size([365, 1, 1])\n",
      "torch.Size([366, 1, 1])\n",
      "torch.Size([367, 1, 1])\n",
      "torch.Size([368, 1, 1])\n",
      "torch.Size([369, 1, 1])\n",
      "torch.Size([370, 1, 1])\n",
      "torch.Size([371, 1, 1])\n",
      "torch.Size([372, 1, 1])\n",
      "torch.Size([373, 1, 1])\n",
      "torch.Size([374, 1, 1])\n",
      "torch.Size([375, 1, 1])\n",
      "torch.Size([376, 1, 1])\n",
      "torch.Size([377, 1, 1])\n",
      "torch.Size([378, 1, 1])\n",
      "torch.Size([379, 1, 1])\n",
      "torch.Size([380, 1, 1])\n",
      "torch.Size([381, 1, 1])\n",
      "torch.Size([382, 1, 1])\n",
      "torch.Size([383, 1, 1])\n",
      "torch.Size([384, 1, 1])\n",
      "torch.Size([385, 1, 1])\n",
      "torch.Size([386, 1, 1])\n",
      "torch.Size([387, 1, 1])\n",
      "torch.Size([388, 1, 1])\n",
      "torch.Size([389, 1, 1])\n",
      "torch.Size([390, 1, 1])\n",
      "torch.Size([391, 1, 1])\n",
      "torch.Size([392, 1, 1])\n",
      "torch.Size([393, 1, 1])\n",
      "torch.Size([394, 1, 1])\n",
      "torch.Size([395, 1, 1])\n",
      "torch.Size([396, 1, 1])\n",
      "torch.Size([397, 1, 1])\n",
      "torch.Size([398, 1, 1])\n",
      "torch.Size([399, 1, 1])\n",
      "torch.Size([400, 1, 1])\n",
      "torch.Size([401, 1, 1])\n",
      "torch.Size([402, 1, 1])\n",
      "torch.Size([403, 1, 1])\n",
      "torch.Size([404, 1, 1])\n",
      "torch.Size([405, 1, 1])\n",
      "torch.Size([406, 1, 1])\n",
      "torch.Size([407, 1, 1])\n",
      "torch.Size([408, 1, 1])\n",
      "torch.Size([409, 1, 1])\n",
      "torch.Size([410, 1, 1])\n",
      "torch.Size([411, 1, 1])\n",
      "torch.Size([412, 1, 1])\n",
      "torch.Size([413, 1, 1])\n",
      "torch.Size([414, 1, 1])\n",
      "torch.Size([415, 1, 1])\n",
      "torch.Size([416, 1, 1])\n",
      "torch.Size([417, 1, 1])\n",
      "torch.Size([418, 1, 1])\n",
      "torch.Size([419, 1, 1])\n",
      "torch.Size([420, 1, 1])\n",
      "torch.Size([421, 1, 1])\n",
      "torch.Size([422, 1, 1])\n",
      "torch.Size([423, 1, 1])\n",
      "torch.Size([424, 1, 1])\n",
      "torch.Size([425, 1, 1])\n",
      "torch.Size([426, 1, 1])\n",
      "torch.Size([427, 1, 1])\n",
      "torch.Size([428, 1, 1])\n",
      "torch.Size([429, 1, 1])\n",
      "torch.Size([430, 1, 1])\n",
      "torch.Size([431, 1, 1])\n",
      "torch.Size([432, 1, 1])\n",
      "torch.Size([433, 1, 1])\n",
      "torch.Size([434, 1, 1])\n",
      "torch.Size([435, 1, 1])\n",
      "torch.Size([436, 1, 1])\n",
      "torch.Size([437, 1, 1])\n",
      "torch.Size([438, 1, 1])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-433f774f384b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0mn_seed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreal_train_X\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0mfinal_dataset_class_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_train_X\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_seed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavez\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'WWT_generated_new'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfinal_dataset_class_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-433f774f384b>\u001b[0m in \u001b[0;36mgenerate_dataset\u001b[0;34m(X, n_seed, n_samples, max_length)\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatapoint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0msrc_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_square_subsequent_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatapoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msrc_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# [S,B,E] --> We want just the predicted timestep S\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m             \u001b[0mone_new_timestep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-ae66456dc4ec>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, src_mask, padding_mask)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInputLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0md_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpositional_encoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpadding_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutputLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# output[...,:9] --> Actual 9 values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, mask, src_key_padding_mask)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmod\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_key_padding_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msrc_key_padding_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, src_mask, src_key_padding_mask)\u001b[0m\n\u001b[1;32m    297\u001b[0m         \u001b[0msrc2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msrc\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m         \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/normalization.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m         return F.layer_norm(\n\u001b[0;32m--> 171\u001b[0;31m             input, self.normalized_shape, self.weight, self.bias, self.eps)\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlayer_norm\u001b[0;34m(input, normalized_shape, weight, bias, eps)\u001b[0m\n\u001b[1;32m   2203\u001b[0m             \u001b[0mlayer_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalized_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2204\u001b[0m         )\n\u001b[0;32m-> 2205\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalized_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "################################# The following is the generating part #################################\n",
    "\n",
    "def generate_dataset(X,n_seed,n_samples,max_length):\n",
    " \n",
    "    generated_dataset_X= torch.empty([0,max_length,1])\n",
    "    datapoint = None\n",
    "    for n in range(n_samples):\n",
    "        \n",
    "        datapoint = get_n_samples(X,n_samples=1) # The first 10 timesteps of just one sample\n",
    "\n",
    "        datapoint = datapoint[:,:n_seed].permute(1,0,2).to(device)\n",
    "\n",
    "        gc.collect(),torch.cuda.empty_cache()\n",
    "        E = datapoint.size(2)\n",
    "        S = datapoint.size(0)\n",
    "        for t in range(max_length-n_seed): # Loop until 550 timesteps\n",
    "            src_mask = model.generate_square_subsequent_mask(S).to(device)\n",
    "            predicted = model(datapoint,src_mask,None).to(device) # [S,B,E] --> We want just the predicted timestep S\n",
    "            one_new_timestep=predicted[-1].unsqueeze(0)\n",
    "            \n",
    "            datapoint = torch.cat((datapoint,one_new_timestep)) # add the forecasted timestep\n",
    "            S = datapoint.size(0)\n",
    "            \n",
    "#             if S == datapoint_len : #FIXED SIZE\n",
    "#                 datapoint = torch.cat((datapoint.cpu(),torch.zeros((max_length-S,1,E)))) # Pad remainings with zero\n",
    "#                 break\n",
    "        \n",
    "            del one_new_timestep\n",
    "        \n",
    "        generated_dataset_X = torch.cat((generated_dataset_X,datapoint.permute(1,0,2).cpu().detach()),axis=0)\n",
    "        if (n%100==0):\n",
    "            print(n)\n",
    "        if (n%1000==0):\n",
    "             np.savez('WWT_generated_new',X=generated_dataset_X)\n",
    "    return generated_dataset_X\n",
    "\n",
    "max_length = 550\n",
    "n_seed = 2\n",
    "n_samples=real_train_X.size(0)\n",
    "final_dataset_class_X = generate_dataset(real_train_X,n_seed=n_seed,n_samples=n_samples,max_length=max_length)\n",
    "\n",
    "np.savez('WWT_generated_new',X=final_dataset_class_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incomplete-wisdom",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
